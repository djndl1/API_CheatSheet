#+TITLE: Unicode

* Prerequisites

** Endianness

Normally this refers to byte endianness, but information can be stored in small or large groups of binary bits. So endianness might refer to endianess of bits (bit numbering, typically used in low-level transmission protocol), octets, hextets, words, etc. The most common positional notation used in mathematics is digit-big-endian: =123456=, with the most significant digit at the first place.

In computing, endianness refers to the ordering of a sequence of storage cells (usually in octets) that represents a primitive data type that can be manipulated by a single hardware instruction. Typically, the first storage cell would be at the lower address of memory. The relation between "significance" of a storage cell in the data and its order determines the endianness.

- /big-endianness/: decreasing numeric significance with increasing memory addresses (or increasing time)

- /little-endianness/: increasing numeric significance with increasing memory addresses (or increasing time)

Some architectures uses different byte endianness for integers and floating-point numbers. Some even has different endianness conventions for words and bytes inside a double-precision number.

Side note: in C, the index of an array member increases with its pointer (virtual memory address).

* UTF-8

The one-byte part are the same as US-ASCII.

The multibyte-byte parts starts with a header byte and several continuation bytes with =10= as their markers. There are three types of bytes: leading bytes (starts with several =1= and then a =0=), continuation bytes (starts with =10=) and ascii bytes (starts with a =0=)

#+begin_src python
A # 0_1100001
α # 110_01110 10_110001
中 # 1110_0100 10_111000 10_101101
#+end_src
