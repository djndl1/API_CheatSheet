{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import theano as th\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 360x1440 with 15 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"61.870407pt\" version=\"1.1\" viewBox=\"0 0 318.088022 61.870407\" width=\"318.088022pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 61.870407 \nL 318.088022 61.870407 \nL 318.088022 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#p94bb5a88e7)\">\n    <image height=\"16\" id=\"imagec7956099ff\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"26.925\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAQdJREFUOI2lUyGug1AQnH6B4QQkSNBFkaeQnKCVCK7SQ2CrSHoCBAJZDYoDEASGE+wyVf2BlvLJ7yaTvLc7b3Z2k3cAQHwRP988XhVwHAciAhGB53m7RPjE+XymiFBE2Lbt7/lyuXDOm2N1hCzLEMcxiqJA3/dIkgTGmP0OXrsEQbCa/+jAcZzFva5r2LYNVUVZlp8dAOD9fmdVVavdSFJVX/NLkjHmo11VXau9E/M85zAMPJ1O/xMAwHEcqaqsqoqqyuPxSJK83W5/LxEAXNdF13WIoggk4fs+pmlC0zTbS5wjDEN2XUcR4TAMNMbQsqwF5/CcYyuu1ysAIE3Tt9ouga34+jc+ACj07ALk1Rr7AAAAAElFTkSuQmCC\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- 0 -->\n    <defs>\n     <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n    </defs>\n    <g transform=\"translate(30.944579 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-48\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g clip-path=\"url(#p28d39aeadd)\">\n    <image height=\"16\" id=\"image08e5274611\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"45.733989\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAMpJREFUOI29kzEKg0AQRZ8S8AiCYOMFLAV7r2Czjbews/UM3sbS2spOW2+gzUyKRMHEKElIPiwMM+znzX7WApQvZH9z+S0D1X3Q/xlYlvUbgstS5HlOHMfroCxLmqY5J+Meo4hg2zegMAxJkoQgCDDGMM8zjuMQRRFd1z3TASoiutSPJ01TnaZJjTF783MDQF3XVRFR3/c3/fURh2E43HUcRwCyLNtfoSiKQwJAq6rStm03vTWFuq4PCQD6vsfzvE1vTeFT/e8zvdIVOENtyTnVqAkAAAAASUVORK5CYII=\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_2\">\n    <!-- 4 -->\n    <defs>\n     <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n    </defs>\n    <g transform=\"translate(49.753567 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-52\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g clip-path=\"url(#p5989b53038)\">\n    <image height=\"16\" id=\"image9c39c167ea\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"64.542978\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAKdJREFUOI21kzsOgzAQRIcUFoVLJN8GidtwI1+Fgo5r0PkCdLY0QpMmNMSJiVFG2mZX+zTaTwNAuKHHneaPAJJY1/UyROcIISjGqLZt32rnyDqY5xnGGDjn6hwAEEktyyJrbclFvuC9F0mRrAMA0LZtIinnXB1gHEeR1DRNdQAA6rpOJDUMQx0Ar7V+mUUZcGxl33f1fV++g5xSStl8c9io1X+e6Rc9AbcTu7OyxTcYAAAAAElFTkSuQmCC\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_3\">\n    <!-- 1 -->\n    <defs>\n     <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n    </defs>\n    <g transform=\"translate(68.562556 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g clip-path=\"url(#p84fe805c81)\">\n    <image height=\"16\" id=\"image5e31e6fd4e\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"83.351966\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAOpJREFUOI3Fkq1uhUAQhee2uN0QDEgUvAKL5Sl4BjwJts8AL4LF4LEYEgQChQXLTE5Vb5o0/LRX9CQjdvLtSc7MPIgI9ILergDbtomZSSl1yOCsxnFEHMdnzPHnLMsgInBd95A5jTBN01XC6xlc6Z2IPr43jDE0zzNpramua4qiiMIwpKZpDk2eeTzPAzPD930URYF1XSEi2Pf93hAdx8GyLKjrGkSEIAjQdR2YGUqp+1sQEZRl+XwPwwBmvm9gWRa2bUPbtkiSBFprMDPyPP/dHVRVhb7vISJI0xTGmB/M48vlr3r5Dv7f4BPV674oAjJICwAAAABJRU5ErkJggg==\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_4\">\n    <!-- 9 -->\n    <defs>\n     <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n    </defs>\n    <g transform=\"translate(87.371545 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-57\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g clip-path=\"url(#pc23a9ee175)\">\n    <image height=\"16\" id=\"image6d46475f82\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"102.160955\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAQFJREFUOI3FkzFug0AURMcxggKJgtIVJQdwZdHQcAXOQENFaSoa34AD+CauOAJ0SJzAQnSzmlQQJ4HIkSPlS6/Yr9nR6P/dHQDhhXp75fLfG5BcKIoClmU9ZaIZkpqmSW3biqTO57P2+70eNSt8HC6Xi0gqyzIBUNM0Iqk4juV5nq7Xq+73u0iuGwCQbdsiqbIsBUC+74ukSCpNUzmOs53gkePxKGPMwjAMq7rd7LJWeZ7DdV0AQFVVcBwHxpjtIc4cDgedTqdPPZKKouibdvUdJEmC2+0Gkui6bivgdgIACsNQ4ziKpPq+F0mFYfjzGr8SBIHqul628OshPlP//5neATZB3NXA9IUZAAAAAElFTkSuQmCC\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_5\">\n    <!-- 2 -->\n    <defs>\n     <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n    </defs>\n    <g transform=\"translate(106.180534 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-50\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_6\">\n   <g clip-path=\"url(#p4698eeb8d1)\">\n    <image height=\"16\" id=\"image974674e5eb\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"120.969944\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAI1JREFUOI21krERQyEMQ0WOjg1oKChZloYlGIMVWMdGv0kZfCRcdOdO6PyQHQDiQq+bx0cBKSWICHLOvwXUWu82KKXAOWd6uJvWGkWEIrL1mAEkqarsvW89JsJaCyQxxth6/l/jiT6yxRipqhQRppS2f+BgnLKqgiS8998jhBDuEPCucc5p3YCNcKLrFh5iSXLE2JJmqwAAAABJRU5ErkJggg==\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_6\">\n    <!-- 1 -->\n    <g transform=\"translate(124.989522 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_7\">\n   <g clip-path=\"url(#p60c4fd0a6a)\">\n    <image height=\"16\" id=\"image52e465c260\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"139.778933\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAOVJREFUOI2tkzGKhEAQRWsWYwPBTNHcE3gOQQw8Tx/AXE9goolxxwbeQMQDmJgYfPkT6Sozi4OzBS+opvrR9aEfIkL5on6+ufwiyPNcAOx0XSdZll1KuAGAAKiUolKKbdtyXVcCYBRFPM4e+G2apiGAvbcsi2maEgDneb4W/EUcxyfxEePdTp7niW3bsiyLiIiEYfhZBht93+95bBlUVfX5Cr7vU2tNrfUumKaJjuPcyyBJkv1FpmleCwzDoOu6p7NxHAmAZVleC+q6fsngyKUgCAIOw/BWUBTFafaxWe7W/36mO/UE1nYfGUzbXHcAAAAASUVORK5CYII=\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_7\">\n    <!-- 3 -->\n    <defs>\n     <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n    </defs>\n    <g transform=\"translate(143.798511 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-51\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_8\">\n   <g clip-path=\"url(#p06974b0239)\">\n    <image height=\"16\" id=\"image1eaff0cf21\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"158.587921\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAHxJREFUOI21krENwCAMBD8uGIQCsQYTsBrzMQCiY4N3itQ4KARLrmy/7uW/ACg2SnaOlwRaa4gxmjtqdSlFRWQ6X7LgnPtGkHNWkhpC+EbgvQcA1FqnO6ZASslEfxVYram/MYaSNL90wUgiyQdT5qDnk9h7N+emhV8Ijgvcg71LZiKBxsgAAAAASUVORK5CYII=\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_8\">\n    <!-- 1 -->\n    <g transform=\"translate(162.6075 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_9\">\n   <g clip-path=\"url(#pd0d39d9233)\">\n    <image height=\"16\" id=\"image5fd1d2c976\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"177.39691\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAOtJREFUOI2lkzGKhEAQRf8sitlkZnoBMfAAXsJEj2FiYijew9RbiImgsScQgw49QFfzJxp3Z3dY3bXgQ79u+lEF3TcAxIX6uHL5V4GIXBMsy4Kqqk5J+C5lWVIpRc/z3p5/ySfkeU7f93feto0iwiAIeL/fjwVZllFrTaUUoyiiiOxZ1/VYAICWZdEYQ2MMy7Kk4zicpolN05wTAGAYhhSRnYuieOFDAQDWdc15num6LgGwbVsOw0Dbts8JANAYwziOdybJJEnOC76n7/sfo/zpKY/jCK010jR92T/dwTNd1+3r23OO/9bl3/gAGHnpNZHJ7OUAAAAASUVORK5CYII=\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_9\">\n    <!-- 4 -->\n    <g transform=\"translate(181.416489 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-52\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_10\">\n   <g clip-path=\"url(#pec13eaa7fb)\">\n    <image height=\"16\" id=\"imagee383f5faa6\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"196.205899\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAANBJREFUOI2lkysOg1AQRadVbymEFeBw7IEdoFCAR5NgWANgsGwBi0M9BBKHxJ2KhrQlJeTBTa6YZOYk83uICHJDzzvFh4A4jqWqKgFkWZZTCJsdx6HrOgDatmXTMAx85+38CcqyBMB1XUQE3/fp+x4ApdQ54MgAURRdB6RpitbaDBCGId9qmsYMsK7rD6Aoir95h3eglJIsywTedzaO4/ka9942AGBZllkLQRAAME0TAHmemwHmef6Zged5ZgDbttFaU9c1SZIctvnYKFd1+xtfgAIYQ2fLNkkAAAAASUVORK5CYII=\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_10\">\n    <!-- 3 -->\n    <g transform=\"translate(200.225478 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-51\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_11\">\n   <g clip-path=\"url(#p41ac0d9de9)\">\n    <image height=\"16\" id=\"image1a1d8a531d\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"215.014888\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAALhJREFUOI3NUrENhDAQcz4S6VmAkizBCtmBCdIwwI/AAEhMQcFEiHQp0pH4K14vPShCNFhycac7yz6dAEDcwOvO8kMFuq7Duq5wzqGua0gpsyLcuSwLQwjfOsbIeZ75O3PA/2ZRFCzLkjFGeu+vCwAgSRpjcsuUAN5HuZRSaJoG0zRh27bT/GK3cYa+7yGEgLX2dCZrcxgGppSYUqL3nm3b5m9wxKqqqLWmc47jOBIAsxFyeOArX8UHq22JURG+CagAAAAASUVORK5CYII=\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_11\">\n    <!-- 5 -->\n    <defs>\n     <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n    </defs>\n    <g transform=\"translate(219.034466 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-53\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_12\">\n   <g clip-path=\"url(#pc79efe11ac)\">\n    <image height=\"16\" id=\"image8c1b914473\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"233.823876\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAANFJREFUOI2tk70NgzAUhC9RGndUmNJD0CPGQAzAFCyAYA8WYBC8BwUMcJcKFBKD8nfSNX66T++k5wsA4QddfwkHAc45kHxx0zSHED2673uRlDFGAGSM0TzPIqllWZRlmZ4ye0CSJCK5e7PWiqRIahzHc8CRu67bIB8DyrLcwm8DhmHYhUiqbVvFcfwe4Dlc1/XRhmFAnudbuKqqs4rn/YuiEEmlaRqc39ZjIAkAmKYJ3vvtSKIoAgBYa18OaFWw86O993LOBTe4rD2+1f8/06e6A+3aGK1RlF/UAAAAAElFTkSuQmCC\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_12\">\n    <!-- 3 -->\n    <g transform=\"translate(237.843455 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-51\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_13\">\n   <g clip-path=\"url(#pe39aa43b85)\">\n    <image height=\"16\" id=\"imaged5b6f52f9b\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"252.632865\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAOFJREFUOI21kS0Og0AQhaf1KAQCS1Zvwmm4BQ6PwaxDg0NyBCThBliCBIlAzeRVQbZNAy1NJ3nJ5O3ut/NzIyLQD3H/5fH/AE3TEDNTURQUx/EpBLbCMAQzPynPc7zes/RsZFmGuq6htQYzoyxLzPMM3/c/AyRJAmYGEe0VbLkx5hzgOA6YGWmaQimFqqowTRO01hAR9H1/DNh+G4YBRLS3siwLRARd150DjDF76bb30Qw2reuKIAiOpn8MUEpBRCAi1wD2FqIougbwPA9t24KZ4bru9wC7nXEc357dNsrVeABdliNsLnQPGQAAAABJRU5ErkJggg==\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_13\">\n    <!-- 6 -->\n    <defs>\n     <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n    </defs>\n    <g transform=\"translate(256.652444 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_14\">\n   <g clip-path=\"url(#p940ee5c966)\">\n    <image height=\"16\" id=\"image9295d4a6e0\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"271.441854\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAGVJREFUOI3FkrsNwDAIRB8u2Zo5PJbH8AYuIFVKfxRk5SQqdA90OgGChErGvAXUWnH3LSRm01oLd5/ugRAWGbzXS5k/ejeDNEBEcoCIfUXuZzDGyAHM7BtAVQHovS8ByyKd6P8iPSJAKpfqyqysAAAAAElFTkSuQmCC\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_14\">\n    <!-- 1 -->\n    <g transform=\"translate(275.461433 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-49\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_15\">\n   <g clip-path=\"url(#p19761e92df)\">\n    <image height=\"16\" id=\"imaged22e17ac66\" transform=\"scale(1 -1)translate(0 -16)\" width=\"16\" x=\"290.250843\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAANNJREFUOI3VU7GJhAAQnHstwcAObMAOLMHIGgRzCxLsQDQScwMDA8FEezCbZS46wX/F+/voByaZXWaXHfYBQPgDvs5EkgiC4G0TfWdRFCL5Q7/geYGkpmn63KAsS5FUlmWfGQBQVVUyM6VpetnzeLlcwcwgCa7rntYPKcRxjL7v4fv+rjmOAwAYhuFyyL5OXdciqa7rDmsmSSKSiqLo/gZN04iktm1TGIaHVOZ5lud590ds21bruoqkzEwkdy7L8n4KL+Z5LjPTOI6/T+EOp7/wvwyeDafgzLkOp3YAAAAASUVORK5CYII=\" y=\"-21.992282\"/>\n   </g>\n   <g id=\"text_15\">\n    <!-- 7 -->\n    <defs>\n     <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n    </defs>\n    <g transform=\"translate(294.270421 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-55\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p94bb5a88e7\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"26.925\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p28d39aeadd\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"45.733989\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p5989b53038\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"64.542978\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p84fe805c81\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"83.351966\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pc23a9ee175\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"102.160955\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p4698eeb8d1\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"120.969944\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p60c4fd0a6a\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"139.778933\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p06974b0239\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"158.587921\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pd0d39d9233\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"177.39691\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pec13eaa7fb\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"196.205899\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p41ac0d9de9\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"215.014888\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pc79efe11ac\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"233.823876\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"pe39aa43b85\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"252.632865\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p940ee5c966\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"271.441854\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p19761e92df\">\n   <rect height=\"15.674157\" width=\"15.674157\" x=\"290.250843\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "num_pics = 15\n",
    "plt.figure(figsize=(5, 20))\n",
    "for i in range(1, num_pics+1):\n",
    "        plt.subplot(1, num_pics, i)\n",
    "        plt.imshow(x_train[i], 'gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(str(y_train[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], np.prod(x_train.shape[1:]))\n",
    "x_test = x_test.reshape(x_test.shape[0], np.prod(x_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid too many transfer to the GPU, \n",
    "# place as many samples in shared variables\n",
    "train_set_x = th.shared(np.asarray(x_train, dtype=th.config.floatX))\n",
    "train_set_y = th.shared(np.asarray(y_train_one_hot, dtype='int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Softmax Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output = y_train_one_hot.shape[1]\n",
    "num_input =  x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "y = T.imatrix('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = th.shared(value=np.random.rand(num_input, num_output),\n",
    "             name='W', borrow=True)\n",
    "b = th.shared(value=np.random.rand(num_output),\n",
    "             name='b', borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = T.nnet.softmax(x.dot(W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = T.argmax(prob, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent = -T.mean(T.sum(\n",
    "                    T.log(prob)*y, axis=-1)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = T.nnet.nnet.categorical_crossentropy(prob, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = T.mean(T.eq(label_pred, T.argmax(y, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW, db = T.grad(cost=cost, wrt=[W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = T.lscalar()\n",
    "batch_size = 500\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer_model = th.function(inputs=[index],\n",
    "                                outputs=[xent, accu, cost],\n",
    "                                updates=[(W, W - learning_rate*dW),\n",
    "                                         (b, b - learning_rate*db)],\n",
    "                                givens={\n",
    "                                    x: train_set_x[index*batch_size:(index+1)*batch_size],\n",
    "                                    y: train_set_y[index*batch_size:(index+1)*batch_size]\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0, minibatch 119/120, training accu 0.8640%, training loss 590.7203714124076, current cost 590.7203714124076\nEpoch 20, minibatch 119/120, training accu 0.8900%, training loss 434.3788458149094, current cost 434.3788458149094\nEpoch 40, minibatch 119/120, training accu 0.9060%, training loss 389.101008047792, current cost 389.101008047792\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9ce0c2031028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcur_iter_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_iter_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_iter_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/theano/tensor/basic.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   5949\u001b[0m         \u001b[0;31m# gives a numpy float object but we need to return a 0d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5950\u001b[0m         \u001b[0;31m# ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5951\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches = x_train.shape[0] // batch_size\n",
    "num_epochs = 1000\n",
    "num_iters = num_batches * num_epochs\n",
    "train_loss = np.zeros(num_iters)\n",
    "train_accu = np.zeros(num_iters)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        cur_iter_idx = epoch * num_batches + batch\n",
    "        train_loss[cur_iter_idx], train_accu[cur_iter_idx], cur_cost = single_layer_model(batch)\n",
    "        \n",
    "    if epoch % 20 == 0:\n",
    "        print(\"Epoch {}, minibatch {}/{}, training accu {:02.4f}%, training loss {}, current cost {}\".format(\n",
    "            epoch, batch, num_batches, train_accu[cur_iter_idx], train_loss[cur_iter_idx], cur_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9053"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = label_pred.eval({x: x_test})\n",
    "np.mean(y_test == y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 600\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test)\n",
    "n_input = np.prod(x_train.shape[1:], dtype=np.int)\n",
    "n_output = np.prod(y_train_one_hot[0].shape, dtype=np.int)\n",
    "\n",
    "x_train_flatten = np.reshape(x_train, (x_train.shape[0], n_input))\n",
    "x_test_flatten = np.reshape(x_test, (x_test.shape[0], n_input))\n",
    "\n",
    "n_hidden = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_glorot_uniform(shape, dtype=th.config.floatX, name='', n=None):\n",
    "    if isinstance(shape, int):\n",
    "        high = np.sqrt(6.0 / shape)\n",
    "    else:\n",
    "        high = np.sqrt(6.0 / (np.sum(shape[:2]) * np.prod(shape[2:])))\n",
    "    shape = shape if n is None else (n,) + shape\n",
    "    \n",
    "    return th.shared(np.asarray(\n",
    "                        np.random.uniform(low=-high, high=high, size=shape),\n",
    "                        dtype=dtype),\n",
    "                    name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_zeros(shape, dtype=th.config.floatX, name='', n=None):\n",
    "    shape = shape if n is None else (n,) + shape\n",
    "    return th.shared(np.zeros(shape, dtype=dtype), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = th.shared(value=np.asarray(x_train_flatten, dtype=th.config.floatX))\n",
    "train_set_y = th.shared(value=np.asarray(y_train_one_hot, dtype='int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.fmatrix()\n",
    "t = T.imatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = T.iscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = shared_glorot_uniform([n_input, n_hidden], name='W1')\n",
    "b1 = shared_zeros((n_hidden, ), name='b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = shared_glorot_uniform([n_hidden, n_output], name='W2')\n",
    "b2 = shared_zeros((n_output, ), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_output = T.tanh(T.dot(x, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_output = T.nnet.softmax(T.dot(hidden_output, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_cost = T.nnet.nnet.categorical_crossentropy(P_output, t).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = T.argmax(P_output, axis=-1)\n",
    "accu = T.mean(T.eq(label_pred, T.argmax(t, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_params = T.grad(cost=xent_cost, wrt=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = [\n",
    "    (param, param - learning_rate * gparam)\n",
    "    for param, gparam in zip(params, grad_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_model = th.function(inputs=[idx],\n",
    "                         outputs=[P_output, accu, xent_cost],\n",
    "                         updates=updates,\n",
    "                         givens={\n",
    "                             x: train_set_x[idx*batch_size: (idx+1)*batch_size],\n",
    "                             t: train_set_y[idx*batch_size: (idx+1)*batch_size]\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0, minibatch 99/100, training accu 0.8917%, current cost 0.41295387585957843\nEpoch 5, minibatch 99/100, training accu 0.9567%, current cost 0.21877751072247822\nEpoch 10, minibatch 99/100, training accu 0.9700%, current cost 0.16829215308030446\nEpoch 15, minibatch 99/100, training accu 0.9700%, current cost 0.14447964866956076\nEpoch 20, minibatch 99/100, training accu 0.9767%, current cost 0.13046157479286194\nEpoch 25, minibatch 99/100, training accu 0.9817%, current cost 0.11502652088801066\nEpoch 30, minibatch 99/100, training accu 0.9833%, current cost 0.10192521373430888\nEpoch 35, minibatch 99/100, training accu 0.9833%, current cost 0.0943093627691269\nEpoch 40, minibatch 99/100, training accu 0.9833%, current cost 0.08802112996578217\nEpoch 45, minibatch 99/100, training accu 0.9850%, current cost 0.0831730822722117\nEpoch 50, minibatch 99/100, training accu 0.9850%, current cost 0.07962940653165182\nEpoch 55, minibatch 99/100, training accu 0.9850%, current cost 0.0763447533051173\nEpoch 60, minibatch 99/100, training accu 0.9850%, current cost 0.07394566575686137\nEpoch 65, minibatch 99/100, training accu 0.9850%, current cost 0.07170249541600546\nEpoch 70, minibatch 99/100, training accu 0.9850%, current cost 0.06974428137143453\nEpoch 75, minibatch 99/100, training accu 0.9850%, current cost 0.06831060369809469\nEpoch 80, minibatch 99/100, training accu 0.9867%, current cost 0.0667434291044871\nEpoch 85, minibatch 99/100, training accu 0.9867%, current cost 0.0649760377407074\nEpoch 90, minibatch 99/100, training accu 0.9883%, current cost 0.06360227187474568\nEpoch 95, minibatch 99/100, training accu 0.9883%, current cost 0.06252425789833069\n"
    }
   ],
   "source": [
    "num_batches = x_train.shape[0] // batch_size\n",
    "num_epochs = 100\n",
    "num_iters = num_batches * num_epochs\n",
    "train_accu = np.zeros(num_iters)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        cur_iter_idx = epoch * num_batches + batch\n",
    "        _, train_accu[cur_iter_idx], cur_cost = two_layer_model(batch)\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch {}, minibatch {}/{}, training accu {:02.4f}%, current cost {}\".format(\n",
    "            epoch, batch, num_batches, train_accu[cur_iter_idx], cur_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9508"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "y_test_pred = label_pred.eval({x: x_test_flatten})\n",
    "np.mean(y_test == y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_validate = x_train[55000:]\n",
    "y_validate = y_train[55000:]\n",
    "x_train = x_train[:55000]\n",
    "y_train = y_train[:55000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = x_train.shape[0]\n",
    "n_test_samples = x_test.shape[0]\n",
    "img_height, img_width = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(n_train_samples, img_height, img_width)\n",
    "x_test = x_test.reshape(n_test_samples, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.tensor.signal import pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_layer:\n",
    "    idx=0\n",
    "    def __init__(self, input, input_shape=None, \n",
    "                 filter_shape=None, n_filters=1, border_mode='valid',\n",
    "                activation=T.nnet.relu, name=None):\n",
    "        \n",
    "        if not name:\n",
    "            W_name = 'Weight_' + str(conv_layer.idx) + '_conv'\n",
    "            b_name = 'bias_' + str(conv_layer.idx) + '_conv'\n",
    "            layer_name = 'conv' + '_' + str(conv_layer.idx) + '_conv'\n",
    "            conv_layer.idx += 1\n",
    "        else:\n",
    "            W_name = 'Weight_' + name\n",
    "            b_name = 'bias_' + name\n",
    "            layer_name = name\n",
    "    \n",
    "        n_channels = input_shape[1]\n",
    "        self._filter_shape = [n_filters, n_channels] + filter_shape\n",
    "\n",
    "        self.W = shared_glorot_uniform(self._filter_shape, name=W_name)\n",
    "        self.b = th.shared(np.asarray(np.random.normal(size=[n_filters,]),\n",
    "                                      dtype=th.config.floatX),\n",
    "                           name=name)\n",
    "                         # broadcastable=(False, True, True))\n",
    "        self._input_tensor = input\n",
    "        self._border_mode = border_mode\n",
    "        self._input_shape = input_shape\n",
    "        self._activation = activation\n",
    "        \n",
    "    def __call__(self):\n",
    "        conv_out = theano.tensor.nnet.conv2d(input=self._input_tensor,\n",
    "                                           filters=self.W,\n",
    "                                           input_shape=self._input_shape,\n",
    "                                           filter_shape=self._filter_shape,\n",
    "                                           border_mode=self._border_mode)\n",
    "        out = self._activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "        return out\n",
    "    \n",
    "    def weights(self):\n",
    "        return [self.W, self.b]\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "x = T.tensor3(name='x')\n",
    "t = T.ivector(name='t')\n",
    "x_input = x.reshape([batch_size, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = conv_layer(input=x_input, \n",
    "                   input_shape=[batch_size, 1, 28, 28],\n",
    "                   n_filters=16,\n",
    "                   filter_shape=[5, 5])\n",
    "conv1_out = conv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1_out = pool.pool_2d(input=conv1_out, ws=[2, 2], ignore_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"NoneType\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-08d6fdeb5c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m conv2 = conv_layer(input=pool1_out,\n\u001b[1;32m      2\u001b[0m                   \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                   n_filters=32)\n\u001b[0m\u001b[1;32m      4\u001b[0m                   \u001b[0;31m#filter_shape=[3, 3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-4de4ae287e02>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input, input_shape, filter_shape, n_filters, border_mode, activation, name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilter_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_glorot_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"NoneType\") to list"
     ]
    }
   ],
   "source": [
    "conv2 = conv_layer(input=pool1_out,\n",
    "                  input_shape=[batch_size, 16, 12, 12],\n",
    "                  n_filters=32,\n",
    "                  filter_shape=[3, 3])\n",
    "conv2_out = conv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2_out = pool.pool_2d(input=conv2_out, ws=[2, 2], ignore_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = pool2_out.flatten(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fc_layer:\n",
    "    idx = 0\n",
    "    \n",
    "    def __init__(self, input, input_length, output_length, \n",
    "                 name=None, activation=T.tanh):\n",
    "              \n",
    "        if not name:\n",
    "            W_name = 'Weight_' + str(fc_layer.idx) + '_fc'\n",
    "            b_name = 'bias_' + str(fc_layer.idx) + '_fc'\n",
    "            layer_name = 'fc' + '_' + str(fc_layer.idx) + '_fc'\n",
    "            fc_layer.idx += 1\n",
    "        else:\n",
    "            W_name = 'Weight_' + name\n",
    "            b_name = 'bias_' + name\n",
    "            layer_name = name\n",
    "\n",
    "        \n",
    "        self.W = shared_glorot_uniform((input_length, output_length), \n",
    "                                  name=W_name)\n",
    "        self.b = shared_glorot_uniform((output_length, ), name=b_name)\n",
    "        self._input = input\n",
    "        self._activation = activation\n",
    "        \n",
    "    def __call__(self):\n",
    "        out = self._activation(T.dot(self._input, self.W) + self.b)\n",
    "        return out\n",
    "    \n",
    "    def weights(self):\n",
    "        return [self.W, self.b]\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "random_seed = int(time.time())\n",
    "rng = np.random.RandomState(random_seed)\n",
    "srng = T.shared_randomstreams.RandomStreams(rng.randint(999999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_layer(input, dropout_rate, size):\n",
    "    if dropout_rate > 0:\n",
    "        mask = srng.binomial(n=1, p=1-dropout_rate, size=size)\n",
    "        return input * T.cast(mask, th.config.floatX)\n",
    "    else:\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = dropout_layer(flattened, dropout_rate, flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = fc_layer(input=flattened, input_length=32*5*5, \n",
    "               output_length=500)\n",
    "fc1_out = fc1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_out = dropout_layer(fc1_out, dropout_rate, fc1_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2 = fc_layer(input=fc1_out, input_length=500, \n",
    "               output_length=10, activation=T.nnet.softmax)\n",
    "fc2_out = fc2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = T.argmax(fc2_out, axis=-1)\n",
    "accu = T.mean(T.eq(pred, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saved_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-6f1b8f2fdb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saved_params' is not defined"
     ]
    }
   ],
   "source": [
    "conv1.W.set_value(saved_params[0].get_value())\n",
    "conv1.b.set_value(saved_params[1].get_value())\n",
    "\n",
    "conv2.W.set_value(saved_params[2].get_value())\n",
    "conv2.b.set_value(saved_params[3].get_value())\n",
    "\n",
    "fc1.W.set_value(saved_params[4].get_value())\n",
    "fc1.b.set_value(saved_params[5].get_value())\n",
    "\n",
    "fc2.W.set_value(saved_params[6].get_value())\n",
    "fc2.b.set_value(saved_params[7].get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = conv1.weights() + conv2.weights() + fc1.weights() + fc2.weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xent_cost = T.nnet.categorical_crossentropy(fc2_out, t).mean()\n",
    "\n",
    "g_params = T.grad(cost=xent_cost, wrt=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_norms(grads, clipnorm):\n",
    "    norm = T.sqrt(sum([T.sum(g**2) for g in grads])) # L2 norm \n",
    "    return [T.switch(T.ge(norm, clipnorm), g*clipnorm / norm, g) for g in grads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = th.shared(np.asarray(x_train, dtype=th.config.floatX))\n",
    "train_set_y = th.shared(np.asarray(y_train, dtype=th.config.floatX))\n",
    "train_set_y = T.cast(train_set_y, 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_validation_model = th.function(inputs=[x, t],\n",
    "                              outputs=[xent_cost, accu])\n",
    "cnn_predict = th.function(inputs=[x], outputs=[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano_utils\n",
    "updates = theano_utils.Adam_update(params=params, g_params=g_params, \n",
    "                                  learning_rate=0.005, forget_first=0.9, forget_second=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano_utils\n",
    "updates = theano_utils.SGD(params=params, g_params=g_params, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano_utils\n",
    "updates = theano_utils.RMSProp_update(params=params, g_params=g_params, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano_utils\n",
    "updates = theano_utils.Adagra_update(params=params, g_params=g_params, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano_utils\n",
    "updates = theano_utils.momentum_SGD_update(params=params, g_params=g_params, \n",
    "                                           learning_rate=0.005, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = T.iscalar('idx')\n",
    "\n",
    "cnn_train_model = th.function(inputs=[idx],\n",
    "                             outputs=[xent_cost, accu, pred],\n",
    "                             updates=updates,\n",
    "                             givens={\n",
    "                                 x: train_set_x[idx*batch_size: (idx+1)*batch_size],\n",
    "                                 t: train_set_y[idx*batch_size: (idx+1)*batch_size]\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 150\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "n_iters = n_epochs * n_batches\n",
    "train_cost_hist = []\n",
    "train_acc_hist = []\n",
    "train_prob_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_interval = 100\n",
    "validate_n_batches = x_validate.shape[0] // batch_size\n",
    "validate_cost_hist = []\n",
    "validate_acc_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cost 2.77397060, train accuracy 0.07800000 at epoch 0 batch 0\n",
      "validation cost 2.76865323, validation accuracy 0.08980000 at epoch 0, batch 0/110\n",
      "train cost 2.46411037, train accuracy 0.14200000 at epoch 0 batch 20\n",
      "train cost 2.31486297, train accuracy 0.19000000 at epoch 0 batch 40\n",
      "train cost 2.13718033, train accuracy 0.26200000 at epoch 0 batch 60\n",
      "train cost 1.97736752, train accuracy 0.32800000 at epoch 0 batch 80\n",
      "train cost 1.79910016, train accuracy 0.37800000 at epoch 0 batch 100\n",
      "validation cost 1.70563624, validation accuracy 0.41080000 at epoch 0, batch 100/110\n",
      "train cost 1.61909258, train accuracy 0.49000000 at epoch 1 batch 10\n",
      "train cost 1.53799748, train accuracy 0.50200000 at epoch 1 batch 30\n",
      "train cost 1.32491457, train accuracy 0.57600000 at epoch 1 batch 50\n",
      "train cost 1.32018125, train accuracy 0.58400000 at epoch 1 batch 70\n",
      "train cost 1.21176243, train accuracy 0.60800000 at epoch 1 batch 90\n",
      "validation cost 1.12549598, validation accuracy 0.65260000 at epoch 1, batch 90/110\n",
      "train cost 1.11431718, train accuracy 0.67000000 at epoch 2 batch 0\n",
      "train cost 1.01185501, train accuracy 0.69000000 at epoch 2 batch 20\n",
      "train cost 0.97851449, train accuracy 0.72000000 at epoch 2 batch 40\n",
      "train cost 1.02169681, train accuracy 0.67800000 at epoch 2 batch 60\n",
      "train cost 0.86426926, train accuracy 0.72600000 at epoch 2 batch 80\n",
      "validation cost 0.83278155, validation accuracy 0.76500000 at epoch 2, batch 80/110\n",
      "train cost 0.96070880, train accuracy 0.69200000 at epoch 2 batch 100\n",
      "train cost 0.81069297, train accuracy 0.76800000 at epoch 3 batch 10\n",
      "train cost 0.74952769, train accuracy 0.79000000 at epoch 3 batch 30\n",
      "train cost 0.70044780, train accuracy 0.79400000 at epoch 3 batch 50\n",
      "train cost 0.72815120, train accuracy 0.79600000 at epoch 3 batch 70\n",
      "validation cost 0.66500226, validation accuracy 0.81840000 at epoch 3, batch 70/110\n",
      "train cost 0.77730715, train accuracy 0.76400000 at epoch 3 batch 90\n",
      "train cost 0.65985179, train accuracy 0.82600000 at epoch 4 batch 0\n",
      "train cost 0.69094765, train accuracy 0.77800000 at epoch 4 batch 20\n",
      "train cost 0.62529570, train accuracy 0.82600000 at epoch 4 batch 40\n",
      "train cost 0.63442290, train accuracy 0.80800000 at epoch 4 batch 60\n",
      "validation cost 0.56683183, validation accuracy 0.84500000 at epoch 4, batch 60/110\n",
      "train cost 0.57470268, train accuracy 0.83600000 at epoch 4 batch 80\n",
      "train cost 0.61533254, train accuracy 0.82200000 at epoch 4 batch 100\n",
      "train cost 0.54308516, train accuracy 0.86400000 at epoch 5 batch 10\n",
      "train cost 0.56174010, train accuracy 0.84400000 at epoch 5 batch 30\n",
      "train cost 0.53790343, train accuracy 0.83000000 at epoch 5 batch 50\n",
      "validation cost 0.49423232, validation accuracy 0.86440000 at epoch 5, batch 50/110\n",
      "train cost 0.51876700, train accuracy 0.85200000 at epoch 5 batch 70\n",
      "train cost 0.54570353, train accuracy 0.83800000 at epoch 5 batch 90\n",
      "train cost 0.47289944, train accuracy 0.89000000 at epoch 6 batch 0\n",
      "train cost 0.47976798, train accuracy 0.87800000 at epoch 6 batch 20\n",
      "train cost 0.51773471, train accuracy 0.85600000 at epoch 6 batch 40\n",
      "validation cost 0.44161718, validation accuracy 0.88020000 at epoch 6, batch 40/110\n",
      "train cost 0.50843954, train accuracy 0.84000000 at epoch 6 batch 60\n",
      "train cost 0.45646712, train accuracy 0.86000000 at epoch 6 batch 80\n",
      "train cost 0.53576261, train accuracy 0.83200000 at epoch 6 batch 100\n",
      "train cost 0.41785452, train accuracy 0.88400000 at epoch 7 batch 10\n",
      "train cost 0.45294088, train accuracy 0.88200000 at epoch 7 batch 30\n",
      "validation cost 0.39849630, validation accuracy 0.89380000 at epoch 7, batch 30/110\n",
      "train cost 0.39847958, train accuracy 0.88400000 at epoch 7 batch 50\n",
      "train cost 0.41361836, train accuracy 0.87800000 at epoch 7 batch 70\n",
      "train cost 0.48234755, train accuracy 0.85600000 at epoch 7 batch 90\n",
      "train cost 0.39109176, train accuracy 0.90000000 at epoch 8 batch 0\n",
      "train cost 0.35423490, train accuracy 0.90000000 at epoch 8 batch 20\n",
      "validation cost 0.35455172, validation accuracy 0.90400000 at epoch 8, batch 20/110\n",
      "train cost 0.43178511, train accuracy 0.86600000 at epoch 8 batch 40\n",
      "train cost 0.41661671, train accuracy 0.88400000 at epoch 8 batch 60\n",
      "train cost 0.37624204, train accuracy 0.89600000 at epoch 8 batch 80\n",
      "train cost 0.45224276, train accuracy 0.87400000 at epoch 8 batch 100\n",
      "train cost 0.35539612, train accuracy 0.89200000 at epoch 9 batch 10\n",
      "validation cost 0.34933493, validation accuracy 0.90520000 at epoch 9, batch 10/110\n",
      "train cost 0.36901119, train accuracy 0.89800000 at epoch 9 batch 30\n",
      "train cost 0.34829751, train accuracy 0.89600000 at epoch 9 batch 50\n",
      "train cost 0.36220309, train accuracy 0.90000000 at epoch 9 batch 70\n",
      "train cost 0.42481446, train accuracy 0.86000000 at epoch 9 batch 90\n",
      "train cost 0.34070647, train accuracy 0.91400000 at epoch 10 batch 0\n",
      "validation cost 0.31432797, validation accuracy 0.91320000 at epoch 10, batch 0/110\n",
      "train cost 0.32799184, train accuracy 0.91800000 at epoch 10 batch 20\n",
      "train cost 0.38523296, train accuracy 0.89600000 at epoch 10 batch 40\n",
      "train cost 0.37152138, train accuracy 0.89600000 at epoch 10 batch 60\n",
      "train cost 0.28819332, train accuracy 0.92200000 at epoch 10 batch 80\n",
      "train cost 0.36867008, train accuracy 0.90800000 at epoch 10 batch 100\n",
      "validation cost 0.29787850, validation accuracy 0.92240000 at epoch 10, batch 100/110\n",
      "train cost 0.35323894, train accuracy 0.89200000 at epoch 11 batch 10\n",
      "train cost 0.32696900, train accuracy 0.90400000 at epoch 11 batch 30\n",
      "train cost 0.31480092, train accuracy 0.91600000 at epoch 11 batch 50\n",
      "train cost 0.31017262, train accuracy 0.91800000 at epoch 11 batch 70\n",
      "train cost 0.30881211, train accuracy 0.90800000 at epoch 11 batch 90\n",
      "validation cost 0.28956697, validation accuracy 0.92080000 at epoch 11, batch 90/110\n",
      "train cost 0.27567005, train accuracy 0.93000000 at epoch 12 batch 0\n",
      "train cost 0.30289993, train accuracy 0.90800000 at epoch 12 batch 20\n",
      "train cost 0.33930776, train accuracy 0.91200000 at epoch 12 batch 40\n",
      "train cost 0.33204871, train accuracy 0.90600000 at epoch 12 batch 60\n",
      "train cost 0.27766263, train accuracy 0.91200000 at epoch 12 batch 80\n",
      "validation cost 0.27398895, validation accuracy 0.92700000 at epoch 12, batch 80/110\n",
      "train cost 0.39051771, train accuracy 0.89200000 at epoch 12 batch 100\n",
      "train cost 0.33622915, train accuracy 0.90000000 at epoch 13 batch 10\n",
      "train cost 0.29979715, train accuracy 0.91000000 at epoch 13 batch 30\n",
      "train cost 0.27080226, train accuracy 0.92600000 at epoch 13 batch 50\n",
      "train cost 0.28885493, train accuracy 0.92400000 at epoch 13 batch 70\n",
      "validation cost 0.25672510, validation accuracy 0.93120000 at epoch 13, batch 70/110\n",
      "train cost 0.31799972, train accuracy 0.90200000 at epoch 13 batch 90\n",
      "train cost 0.27682492, train accuracy 0.91800000 at epoch 14 batch 0\n",
      "train cost 0.32288849, train accuracy 0.89400000 at epoch 14 batch 20\n",
      "train cost 0.31229505, train accuracy 0.92200000 at epoch 14 batch 40\n",
      "train cost 0.30694997, train accuracy 0.91800000 at epoch 14 batch 60\n",
      "validation cost 0.25275408, validation accuracy 0.92720000 at epoch 14, batch 60/110\n",
      "train cost 0.28191158, train accuracy 0.92400000 at epoch 14 batch 80\n",
      "train cost 0.33557242, train accuracy 0.89800000 at epoch 14 batch 100\n",
      "train cost 0.28349519, train accuracy 0.91800000 at epoch 15 batch 10\n",
      "train cost 0.26901004, train accuracy 0.91200000 at epoch 15 batch 30\n",
      "train cost 0.23002848, train accuracy 0.93200000 at epoch 15 batch 50\n",
      "validation cost 0.23789995, validation accuracy 0.93620000 at epoch 15, batch 50/110\n",
      "train cost 0.23651364, train accuracy 0.95200000 at epoch 15 batch 70\n",
      "train cost 0.28404304, train accuracy 0.91400000 at epoch 15 batch 90\n",
      "train cost 0.23564024, train accuracy 0.93400000 at epoch 16 batch 0\n",
      "train cost 0.26674402, train accuracy 0.92000000 at epoch 16 batch 20\n",
      "train cost 0.31485471, train accuracy 0.89600000 at epoch 16 batch 40\n",
      "validation cost 0.22521634, validation accuracy 0.93900000 at epoch 16, batch 40/110\n",
      "train cost 0.26161322, train accuracy 0.91400000 at epoch 16 batch 60\n",
      "train cost 0.22923522, train accuracy 0.92800000 at epoch 16 batch 80\n",
      "train cost 0.30764991, train accuracy 0.91400000 at epoch 16 batch 100\n",
      "train cost 0.27917627, train accuracy 0.91800000 at epoch 17 batch 10\n",
      "train cost 0.23092231, train accuracy 0.93800000 at epoch 17 batch 30\n",
      "validation cost 0.22330195, validation accuracy 0.93660000 at epoch 17, batch 30/110\n",
      "train cost 0.25109857, train accuracy 0.92800000 at epoch 17 batch 50\n",
      "train cost 0.22309904, train accuracy 0.93600000 at epoch 17 batch 70\n",
      "train cost 0.24743801, train accuracy 0.92800000 at epoch 17 batch 90\n",
      "train cost 0.22047292, train accuracy 0.94400000 at epoch 18 batch 0\n",
      "train cost 0.24693722, train accuracy 0.93000000 at epoch 18 batch 20\n",
      "validation cost 0.21229051, validation accuracy 0.93900000 at epoch 18, batch 20/110\n",
      "train cost 0.24821237, train accuracy 0.93000000 at epoch 18 batch 40\n",
      "train cost 0.22014001, train accuracy 0.93400000 at epoch 18 batch 60\n",
      "train cost 0.16924062, train accuracy 0.95800000 at epoch 18 batch 80\n",
      "train cost 0.28480893, train accuracy 0.92400000 at epoch 18 batch 100\n",
      "train cost 0.26463124, train accuracy 0.92000000 at epoch 19 batch 10\n",
      "validation cost 0.21617894, validation accuracy 0.93980000 at epoch 19, batch 10/110\n",
      "train cost 0.22745341, train accuracy 0.93200000 at epoch 19 batch 30\n",
      "train cost 0.20881379, train accuracy 0.93200000 at epoch 19 batch 50\n",
      "train cost 0.22844404, train accuracy 0.94200000 at epoch 19 batch 70\n",
      "train cost 0.24245064, train accuracy 0.93200000 at epoch 19 batch 90\n",
      "train cost 0.23563620, train accuracy 0.94000000 at epoch 20 batch 0\n",
      "validation cost 0.20075651, validation accuracy 0.94400000 at epoch 20, batch 0/110\n",
      "train cost 0.26077735, train accuracy 0.93200000 at epoch 20 batch 20\n",
      "train cost 0.23293051, train accuracy 0.93000000 at epoch 20 batch 40\n",
      "train cost 0.21873172, train accuracy 0.93800000 at epoch 20 batch 60\n",
      "train cost 0.18578626, train accuracy 0.94400000 at epoch 20 batch 80\n",
      "train cost 0.30301589, train accuracy 0.90200000 at epoch 20 batch 100\n",
      "validation cost 0.19890873, validation accuracy 0.94580000 at epoch 20, batch 100/110\n",
      "train cost 0.21157439, train accuracy 0.93600000 at epoch 21 batch 10\n",
      "train cost 0.19547121, train accuracy 0.94600000 at epoch 21 batch 30\n",
      "train cost 0.21685755, train accuracy 0.94000000 at epoch 21 batch 50\n",
      "train cost 0.23183037, train accuracy 0.93000000 at epoch 21 batch 70\n",
      "train cost 0.23665473, train accuracy 0.92600000 at epoch 21 batch 90\n",
      "validation cost 0.18930351, validation accuracy 0.94620000 at epoch 21, batch 90/110\n",
      "train cost 0.21654209, train accuracy 0.93600000 at epoch 22 batch 0\n",
      "train cost 0.22508731, train accuracy 0.92600000 at epoch 22 batch 20\n",
      "train cost 0.25328073, train accuracy 0.93000000 at epoch 22 batch 40\n",
      "train cost 0.20529830, train accuracy 0.94600000 at epoch 22 batch 60\n",
      "train cost 0.18390585, train accuracy 0.94400000 at epoch 22 batch 80\n",
      "validation cost 0.19001555, validation accuracy 0.94280000 at epoch 22, batch 80/110\n",
      "train cost 0.27233878, train accuracy 0.92200000 at epoch 22 batch 100\n",
      "train cost 0.22082900, train accuracy 0.94800000 at epoch 23 batch 10\n",
      "train cost 0.21310076, train accuracy 0.93400000 at epoch 23 batch 30\n",
      "train cost 0.21191429, train accuracy 0.94000000 at epoch 23 batch 50\n",
      "train cost 0.20698312, train accuracy 0.94800000 at epoch 23 batch 70\n",
      "validation cost 0.18363480, validation accuracy 0.94940000 at epoch 23, batch 70/110\n",
      "train cost 0.21213956, train accuracy 0.93800000 at epoch 23 batch 90\n",
      "train cost 0.20240611, train accuracy 0.94800000 at epoch 24 batch 0\n",
      "train cost 0.22161250, train accuracy 0.93600000 at epoch 24 batch 20\n",
      "train cost 0.21189822, train accuracy 0.94000000 at epoch 24 batch 40\n",
      "train cost 0.18141694, train accuracy 0.95000000 at epoch 24 batch 60\n",
      "validation cost 0.17631064, validation accuracy 0.94820000 at epoch 24, batch 60/110\n",
      "train cost 0.19965684, train accuracy 0.94000000 at epoch 24 batch 80\n",
      "train cost 0.27546769, train accuracy 0.92200000 at epoch 24 batch 100\n",
      "train cost 0.18715955, train accuracy 0.94800000 at epoch 25 batch 10\n",
      "train cost 0.19749585, train accuracy 0.94800000 at epoch 25 batch 30\n",
      "train cost 0.18514732, train accuracy 0.94600000 at epoch 25 batch 50\n",
      "validation cost 0.17857178, validation accuracy 0.95200000 at epoch 25, batch 50/110\n",
      "train cost 0.21994844, train accuracy 0.92600000 at epoch 25 batch 70\n",
      "train cost 0.20758897, train accuracy 0.92600000 at epoch 25 batch 90\n",
      "train cost 0.21375655, train accuracy 0.95600000 at epoch 26 batch 0\n",
      "train cost 0.21719982, train accuracy 0.93400000 at epoch 26 batch 20\n",
      "train cost 0.22627179, train accuracy 0.93600000 at epoch 26 batch 40\n",
      "validation cost 0.17797426, validation accuracy 0.94860000 at epoch 26, batch 40/110\n",
      "train cost 0.19731301, train accuracy 0.95400000 at epoch 26 batch 60\n",
      "train cost 0.14957047, train accuracy 0.95000000 at epoch 26 batch 80\n",
      "train cost 0.24461684, train accuracy 0.92800000 at epoch 26 batch 100\n",
      "train cost 0.19642787, train accuracy 0.94000000 at epoch 27 batch 10\n",
      "train cost 0.17091635, train accuracy 0.95200000 at epoch 27 batch 30\n",
      "validation cost 0.16851378, validation accuracy 0.95400000 at epoch 27, batch 30/110\n",
      "train cost 0.18254429, train accuracy 0.92800000 at epoch 27 batch 50\n",
      "train cost 0.17653693, train accuracy 0.95600000 at epoch 27 batch 70\n",
      "train cost 0.19205333, train accuracy 0.93600000 at epoch 27 batch 90\n",
      "train cost 0.20839207, train accuracy 0.94800000 at epoch 28 batch 0\n",
      "train cost 0.21668021, train accuracy 0.93600000 at epoch 28 batch 20\n",
      "validation cost 0.18263693, validation accuracy 0.94980000 at epoch 28, batch 20/110\n",
      "train cost 0.21302952, train accuracy 0.93800000 at epoch 28 batch 40\n",
      "train cost 0.20128788, train accuracy 0.93400000 at epoch 28 batch 60\n",
      "train cost 0.18483105, train accuracy 0.94200000 at epoch 28 batch 80\n",
      "train cost 0.23321870, train accuracy 0.93800000 at epoch 28 batch 100\n",
      "train cost 0.19582249, train accuracy 0.95400000 at epoch 29 batch 10\n",
      "validation cost 0.16270355, validation accuracy 0.95940000 at epoch 29, batch 10/110\n",
      "train cost 0.20025833, train accuracy 0.94400000 at epoch 29 batch 30\n",
      "train cost 0.14934194, train accuracy 0.95200000 at epoch 29 batch 50\n",
      "train cost 0.18804944, train accuracy 0.94400000 at epoch 29 batch 70\n",
      "train cost 0.18057303, train accuracy 0.94200000 at epoch 29 batch 90\n",
      "train cost 0.16888364, train accuracy 0.95400000 at epoch 30 batch 0\n",
      "validation cost 0.16075981, validation accuracy 0.95480000 at epoch 30, batch 0/110\n",
      "train cost 0.20688190, train accuracy 0.93600000 at epoch 30 batch 20\n",
      "train cost 0.18485984, train accuracy 0.94800000 at epoch 30 batch 40\n",
      "train cost 0.19146501, train accuracy 0.94000000 at epoch 30 batch 60\n",
      "train cost 0.14030515, train accuracy 0.96000000 at epoch 30 batch 80\n",
      "train cost 0.21238138, train accuracy 0.93800000 at epoch 30 batch 100\n",
      "validation cost 0.16452062, validation accuracy 0.95260000 at epoch 30, batch 100/110\n",
      "train cost 0.18201816, train accuracy 0.95200000 at epoch 31 batch 10\n",
      "train cost 0.18125056, train accuracy 0.94200000 at epoch 31 batch 30\n",
      "train cost 0.16789851, train accuracy 0.94000000 at epoch 31 batch 50\n",
      "train cost 0.17076993, train accuracy 0.95800000 at epoch 31 batch 70\n",
      "train cost 0.16220002, train accuracy 0.94000000 at epoch 31 batch 90\n",
      "validation cost 0.15345435, validation accuracy 0.95660000 at epoch 31, batch 90/110\n",
      "train cost 0.15897386, train accuracy 0.95200000 at epoch 32 batch 0\n",
      "train cost 0.23443477, train accuracy 0.92800000 at epoch 32 batch 20\n",
      "train cost 0.18544361, train accuracy 0.94000000 at epoch 32 batch 40\n",
      "train cost 0.16250382, train accuracy 0.95400000 at epoch 32 batch 60\n",
      "train cost 0.18499048, train accuracy 0.93800000 at epoch 32 batch 80\n",
      "validation cost 0.15627518, validation accuracy 0.95660000 at epoch 32, batch 80/110\n",
      "train cost 0.24521489, train accuracy 0.93400000 at epoch 32 batch 100\n",
      "train cost 0.18340416, train accuracy 0.94000000 at epoch 33 batch 10\n",
      "train cost 0.16595383, train accuracy 0.95000000 at epoch 33 batch 30\n",
      "train cost 0.13305824, train accuracy 0.95600000 at epoch 33 batch 50\n",
      "train cost 0.13869137, train accuracy 0.96200000 at epoch 33 batch 70\n",
      "validation cost 0.14642029, validation accuracy 0.95880000 at epoch 33, batch 70/110\n",
      "train cost 0.22522230, train accuracy 0.91000000 at epoch 33 batch 90\n",
      "train cost 0.16712639, train accuracy 0.94800000 at epoch 34 batch 0\n",
      "train cost 0.18766101, train accuracy 0.94000000 at epoch 34 batch 20\n",
      "train cost 0.19197413, train accuracy 0.94400000 at epoch 34 batch 40\n",
      "train cost 0.16878596, train accuracy 0.95000000 at epoch 34 batch 60\n",
      "validation cost 0.14553472, validation accuracy 0.95620000 at epoch 34, batch 60/110\n",
      "train cost 0.14609908, train accuracy 0.96000000 at epoch 34 batch 80\n",
      "train cost 0.20236377, train accuracy 0.93800000 at epoch 34 batch 100\n",
      "train cost 0.17335553, train accuracy 0.94600000 at epoch 35 batch 10\n",
      "train cost 0.15888043, train accuracy 0.95000000 at epoch 35 batch 30\n",
      "train cost 0.15944439, train accuracy 0.94000000 at epoch 35 batch 50\n",
      "validation cost 0.15167123, validation accuracy 0.95780000 at epoch 35, batch 50/110\n",
      "train cost 0.16999811, train accuracy 0.95600000 at epoch 35 batch 70\n",
      "train cost 0.15847856, train accuracy 0.95400000 at epoch 35 batch 90\n",
      "train cost 0.20438282, train accuracy 0.94000000 at epoch 36 batch 0\n",
      "train cost 0.17637202, train accuracy 0.95200000 at epoch 36 batch 20\n",
      "train cost 0.19177952, train accuracy 0.94200000 at epoch 36 batch 40\n",
      "validation cost 0.15706382, validation accuracy 0.95440000 at epoch 36, batch 40/110\n",
      "train cost 0.17039602, train accuracy 0.93600000 at epoch 36 batch 60\n",
      "train cost 0.14765693, train accuracy 0.96000000 at epoch 36 batch 80\n",
      "train cost 0.22510399, train accuracy 0.94000000 at epoch 36 batch 100\n",
      "train cost 0.17643520, train accuracy 0.95000000 at epoch 37 batch 10\n",
      "train cost 0.15965316, train accuracy 0.95200000 at epoch 37 batch 30\n",
      "validation cost 0.14063380, validation accuracy 0.96120000 at epoch 37, batch 30/110\n",
      "train cost 0.14206815, train accuracy 0.96800000 at epoch 37 batch 50\n",
      "train cost 0.14847048, train accuracy 0.95800000 at epoch 37 batch 70\n",
      "train cost 0.17115638, train accuracy 0.94200000 at epoch 37 batch 90\n",
      "train cost 0.17206171, train accuracy 0.95600000 at epoch 38 batch 0\n",
      "train cost 0.18628885, train accuracy 0.94400000 at epoch 38 batch 20\n",
      "validation cost 0.14264828, validation accuracy 0.96000000 at epoch 38, batch 20/110\n",
      "train cost 0.17074983, train accuracy 0.95000000 at epoch 38 batch 40\n",
      "train cost 0.16182481, train accuracy 0.95200000 at epoch 38 batch 60\n",
      "train cost 0.15389262, train accuracy 0.95200000 at epoch 38 batch 80\n",
      "train cost 0.20343223, train accuracy 0.93600000 at epoch 38 batch 100\n",
      "train cost 0.19371733, train accuracy 0.96000000 at epoch 39 batch 10\n",
      "validation cost 0.13873313, validation accuracy 0.95860000 at epoch 39, batch 10/110\n",
      "train cost 0.16715667, train accuracy 0.94600000 at epoch 39 batch 30\n",
      "train cost 0.15223689, train accuracy 0.95200000 at epoch 39 batch 50\n",
      "train cost 0.14757691, train accuracy 0.96000000 at epoch 39 batch 70\n",
      "train cost 0.16931123, train accuracy 0.95200000 at epoch 39 batch 90\n",
      "train cost 0.14198987, train accuracy 0.95600000 at epoch 40 batch 0\n",
      "validation cost 0.13880869, validation accuracy 0.96040000 at epoch 40, batch 0/110\n",
      "train cost 0.16966954, train accuracy 0.95600000 at epoch 40 batch 20\n",
      "train cost 0.19701737, train accuracy 0.94400000 at epoch 40 batch 40\n",
      "train cost 0.16458546, train accuracy 0.95000000 at epoch 40 batch 60\n",
      "train cost 0.14975807, train accuracy 0.95800000 at epoch 40 batch 80\n",
      "train cost 0.19114740, train accuracy 0.94000000 at epoch 40 batch 100\n",
      "validation cost 0.14155650, validation accuracy 0.95900000 at epoch 40, batch 100/110\n",
      "train cost 0.17553821, train accuracy 0.96200000 at epoch 41 batch 10\n",
      "train cost 0.15043633, train accuracy 0.95400000 at epoch 41 batch 30\n",
      "train cost 0.11910970, train accuracy 0.96600000 at epoch 41 batch 50\n",
      "train cost 0.15752837, train accuracy 0.95600000 at epoch 41 batch 70\n",
      "train cost 0.17433532, train accuracy 0.95200000 at epoch 41 batch 90\n",
      "validation cost 0.13891575, validation accuracy 0.96080000 at epoch 41, batch 90/110\n",
      "train cost 0.16123699, train accuracy 0.96000000 at epoch 42 batch 0\n",
      "train cost 0.16231874, train accuracy 0.95400000 at epoch 42 batch 20\n",
      "train cost 0.19206412, train accuracy 0.94400000 at epoch 42 batch 40\n",
      "train cost 0.14546184, train accuracy 0.96000000 at epoch 42 batch 60\n",
      "train cost 0.13339469, train accuracy 0.96400000 at epoch 42 batch 80\n",
      "validation cost 0.13697810, validation accuracy 0.95940000 at epoch 42, batch 80/110\n",
      "train cost 0.15392083, train accuracy 0.96200000 at epoch 42 batch 100\n",
      "train cost 0.16346048, train accuracy 0.95800000 at epoch 43 batch 10\n",
      "train cost 0.15902837, train accuracy 0.96000000 at epoch 43 batch 30\n",
      "train cost 0.14713161, train accuracy 0.94600000 at epoch 43 batch 50\n",
      "train cost 0.12792218, train accuracy 0.96400000 at epoch 43 batch 70\n",
      "validation cost 0.13070878, validation accuracy 0.96060000 at epoch 43, batch 70/110\n",
      "train cost 0.16046327, train accuracy 0.94600000 at epoch 43 batch 90\n",
      "train cost 0.16322456, train accuracy 0.94800000 at epoch 44 batch 0\n",
      "train cost 0.16619651, train accuracy 0.95800000 at epoch 44 batch 20\n",
      "train cost 0.18603474, train accuracy 0.94000000 at epoch 44 batch 40\n",
      "train cost 0.13226767, train accuracy 0.95400000 at epoch 44 batch 60\n",
      "validation cost 0.13458662, validation accuracy 0.96120000 at epoch 44, batch 60/110\n",
      "train cost 0.14850923, train accuracy 0.95000000 at epoch 44 batch 80\n",
      "train cost 0.18564363, train accuracy 0.95000000 at epoch 44 batch 100\n",
      "train cost 0.16591172, train accuracy 0.95600000 at epoch 45 batch 10\n",
      "train cost 0.15567686, train accuracy 0.95400000 at epoch 45 batch 30\n",
      "train cost 0.11729358, train accuracy 0.95800000 at epoch 45 batch 50\n",
      "validation cost 0.12827275, validation accuracy 0.96300000 at epoch 45, batch 50/110\n",
      "train cost 0.11567568, train accuracy 0.96800000 at epoch 45 batch 70\n",
      "train cost 0.14684688, train accuracy 0.95800000 at epoch 45 batch 90\n",
      "train cost 0.15769927, train accuracy 0.96000000 at epoch 46 batch 0\n",
      "train cost 0.18027726, train accuracy 0.93800000 at epoch 46 batch 20\n",
      "train cost 0.17635840, train accuracy 0.95400000 at epoch 46 batch 40\n",
      "validation cost 0.13325680, validation accuracy 0.96420000 at epoch 46, batch 40/110\n",
      "train cost 0.11965106, train accuracy 0.96000000 at epoch 46 batch 60\n",
      "train cost 0.12957276, train accuracy 0.96200000 at epoch 46 batch 80\n",
      "train cost 0.17923419, train accuracy 0.93800000 at epoch 46 batch 100\n",
      "train cost 0.13673395, train accuracy 0.97200000 at epoch 47 batch 10\n",
      "train cost 0.13883564, train accuracy 0.95200000 at epoch 47 batch 30\n",
      "validation cost 0.12817304, validation accuracy 0.96180000 at epoch 47, batch 30/110\n",
      "train cost 0.12493390, train accuracy 0.95800000 at epoch 47 batch 50\n",
      "train cost 0.12672360, train accuracy 0.97800000 at epoch 47 batch 70\n",
      "train cost 0.15591286, train accuracy 0.95200000 at epoch 47 batch 90\n",
      "train cost 0.11881030, train accuracy 0.97000000 at epoch 48 batch 0\n",
      "train cost 0.17512386, train accuracy 0.95200000 at epoch 48 batch 20\n",
      "validation cost 0.12640132, validation accuracy 0.96080000 at epoch 48, batch 20/110\n",
      "train cost 0.15522820, train accuracy 0.95600000 at epoch 48 batch 40\n",
      "train cost 0.13006453, train accuracy 0.96200000 at epoch 48 batch 60\n",
      "train cost 0.11345838, train accuracy 0.96800000 at epoch 48 batch 80\n",
      "train cost 0.16121076, train accuracy 0.95600000 at epoch 48 batch 100\n",
      "train cost 0.12747309, train accuracy 0.96800000 at epoch 49 batch 10\n",
      "validation cost 0.12817340, validation accuracy 0.96140000 at epoch 49, batch 10/110\n",
      "train cost 0.15879571, train accuracy 0.96200000 at epoch 49 batch 30\n",
      "train cost 0.15142711, train accuracy 0.95400000 at epoch 49 batch 50\n",
      "train cost 0.13344575, train accuracy 0.96200000 at epoch 49 batch 70\n",
      "train cost 0.17083594, train accuracy 0.94000000 at epoch 49 batch 90\n",
      "train cost 0.16655718, train accuracy 0.94600000 at epoch 50 batch 0\n",
      "validation cost 0.12655447, validation accuracy 0.96280000 at epoch 50, batch 0/110\n",
      "train cost 0.15788777, train accuracy 0.95400000 at epoch 50 batch 20\n",
      "train cost 0.17933127, train accuracy 0.94000000 at epoch 50 batch 40\n",
      "train cost 0.10960910, train accuracy 0.97200000 at epoch 50 batch 60\n",
      "train cost 0.11695675, train accuracy 0.96000000 at epoch 50 batch 80\n",
      "train cost 0.16656759, train accuracy 0.95000000 at epoch 50 batch 100\n",
      "validation cost 0.11879785, validation accuracy 0.96900000 at epoch 50, batch 100/110\n",
      "train cost 0.12624566, train accuracy 0.95400000 at epoch 51 batch 10\n",
      "train cost 0.14607173, train accuracy 0.95000000 at epoch 51 batch 30\n",
      "train cost 0.11490848, train accuracy 0.95600000 at epoch 51 batch 50\n",
      "train cost 0.12676217, train accuracy 0.96800000 at epoch 51 batch 70\n",
      "train cost 0.13210538, train accuracy 0.95800000 at epoch 51 batch 90\n",
      "validation cost 0.11653759, validation accuracy 0.96700000 at epoch 51, batch 90/110\n",
      "train cost 0.14518458, train accuracy 0.96000000 at epoch 52 batch 0\n",
      "train cost 0.17929907, train accuracy 0.94800000 at epoch 52 batch 20\n",
      "train cost 0.16172278, train accuracy 0.94400000 at epoch 52 batch 40\n",
      "train cost 0.14503601, train accuracy 0.95600000 at epoch 52 batch 60\n",
      "train cost 0.12189785, train accuracy 0.95800000 at epoch 52 batch 80\n",
      "validation cost 0.12646664, validation accuracy 0.96640000 at epoch 52, batch 80/110\n",
      "train cost 0.18122315, train accuracy 0.93600000 at epoch 52 batch 100\n",
      "train cost 0.13912730, train accuracy 0.96400000 at epoch 53 batch 10\n",
      "train cost 0.13382035, train accuracy 0.96400000 at epoch 53 batch 30\n",
      "train cost 0.11070612, train accuracy 0.97200000 at epoch 53 batch 50\n",
      "train cost 0.12292007, train accuracy 0.96400000 at epoch 53 batch 70\n",
      "validation cost 0.12018409, validation accuracy 0.96260000 at epoch 53, batch 70/110\n",
      "train cost 0.13804270, train accuracy 0.96000000 at epoch 53 batch 90\n",
      "train cost 0.15341920, train accuracy 0.95000000 at epoch 54 batch 0\n",
      "train cost 0.14778650, train accuracy 0.96200000 at epoch 54 batch 20\n",
      "train cost 0.15956758, train accuracy 0.95600000 at epoch 54 batch 40\n",
      "train cost 0.13638468, train accuracy 0.95800000 at epoch 54 batch 60\n",
      "validation cost 0.12170596, validation accuracy 0.96200000 at epoch 54, batch 60/110\n",
      "train cost 0.11301354, train accuracy 0.97200000 at epoch 54 batch 80\n",
      "train cost 0.17638545, train accuracy 0.94800000 at epoch 54 batch 100\n",
      "train cost 0.15621641, train accuracy 0.96200000 at epoch 55 batch 10\n",
      "train cost 0.16118707, train accuracy 0.94600000 at epoch 55 batch 30\n",
      "train cost 0.13158920, train accuracy 0.96000000 at epoch 55 batch 50\n",
      "validation cost 0.12122106, validation accuracy 0.96460000 at epoch 55, batch 50/110\n",
      "train cost 0.12122764, train accuracy 0.96600000 at epoch 55 batch 70\n",
      "train cost 0.13283843, train accuracy 0.95200000 at epoch 55 batch 90\n",
      "train cost 0.10520348, train accuracy 0.97200000 at epoch 56 batch 0\n",
      "train cost 0.19095398, train accuracy 0.94000000 at epoch 56 batch 20\n",
      "train cost 0.14192389, train accuracy 0.95200000 at epoch 56 batch 40\n",
      "validation cost 0.11962447, validation accuracy 0.96460000 at epoch 56, batch 40/110\n",
      "train cost 0.14130588, train accuracy 0.95400000 at epoch 56 batch 60\n",
      "train cost 0.12582311, train accuracy 0.95800000 at epoch 56 batch 80\n",
      "train cost 0.18814610, train accuracy 0.94200000 at epoch 56 batch 100\n",
      "train cost 0.14820680, train accuracy 0.96000000 at epoch 57 batch 10\n",
      "train cost 0.10946947, train accuracy 0.97600000 at epoch 57 batch 30\n",
      "validation cost 0.11772255, validation accuracy 0.96700000 at epoch 57, batch 30/110\n",
      "train cost 0.07829924, train accuracy 0.97800000 at epoch 57 batch 50\n",
      "train cost 0.11557790, train accuracy 0.96200000 at epoch 57 batch 70\n",
      "train cost 0.11680005, train accuracy 0.96400000 at epoch 57 batch 90\n",
      "train cost 0.13092199, train accuracy 0.97200000 at epoch 58 batch 0\n",
      "train cost 0.15358143, train accuracy 0.95800000 at epoch 58 batch 20\n",
      "validation cost 0.11219148, validation accuracy 0.96800000 at epoch 58, batch 20/110\n",
      "train cost 0.16276439, train accuracy 0.95200000 at epoch 58 batch 40\n",
      "train cost 0.12208381, train accuracy 0.97200000 at epoch 58 batch 60\n",
      "train cost 0.12240615, train accuracy 0.96600000 at epoch 58 batch 80\n",
      "train cost 0.17136471, train accuracy 0.95600000 at epoch 58 batch 100\n",
      "train cost 0.14144103, train accuracy 0.96400000 at epoch 59 batch 10\n",
      "validation cost 0.11773392, validation accuracy 0.96600000 at epoch 59, batch 10/110\n",
      "train cost 0.12612984, train accuracy 0.96200000 at epoch 59 batch 30\n",
      "train cost 0.08385090, train accuracy 0.97600000 at epoch 59 batch 50\n",
      "train cost 0.14174612, train accuracy 0.95000000 at epoch 59 batch 70\n",
      "train cost 0.14506076, train accuracy 0.95200000 at epoch 59 batch 90\n",
      "train cost 0.12750097, train accuracy 0.95600000 at epoch 60 batch 0\n",
      "validation cost 0.11434041, validation accuracy 0.96720000 at epoch 60, batch 0/110\n",
      "train cost 0.14632981, train accuracy 0.96000000 at epoch 60 batch 20\n",
      "train cost 0.14895625, train accuracy 0.95800000 at epoch 60 batch 40\n",
      "train cost 0.12843977, train accuracy 0.95400000 at epoch 60 batch 60\n",
      "train cost 0.11379710, train accuracy 0.96600000 at epoch 60 batch 80\n",
      "train cost 0.15859714, train accuracy 0.96800000 at epoch 60 batch 100\n",
      "validation cost 0.10942866, validation accuracy 0.96900000 at epoch 60, batch 100/110\n",
      "train cost 0.13140476, train accuracy 0.96600000 at epoch 61 batch 10\n",
      "train cost 0.10724809, train accuracy 0.97000000 at epoch 61 batch 30\n",
      "train cost 0.11438421, train accuracy 0.96000000 at epoch 61 batch 50\n",
      "train cost 0.12777340, train accuracy 0.97200000 at epoch 61 batch 70\n",
      "train cost 0.12452628, train accuracy 0.95600000 at epoch 61 batch 90\n",
      "validation cost 0.11897274, validation accuracy 0.96540000 at epoch 61, batch 90/110\n",
      "train cost 0.13093005, train accuracy 0.96200000 at epoch 62 batch 0\n",
      "train cost 0.14012858, train accuracy 0.95200000 at epoch 62 batch 20\n",
      "train cost 0.14065659, train accuracy 0.96600000 at epoch 62 batch 40\n",
      "train cost 0.09848810, train accuracy 0.97200000 at epoch 62 batch 60\n",
      "train cost 0.13235417, train accuracy 0.95800000 at epoch 62 batch 80\n",
      "validation cost 0.10461593, validation accuracy 0.96840000 at epoch 62, batch 80/110\n",
      "train cost 0.12984139, train accuracy 0.95800000 at epoch 62 batch 100\n",
      "train cost 0.10846301, train accuracy 0.96600000 at epoch 63 batch 10\n",
      "train cost 0.11536388, train accuracy 0.96400000 at epoch 63 batch 30\n",
      "train cost 0.10388514, train accuracy 0.96400000 at epoch 63 batch 50\n",
      "train cost 0.16285142, train accuracy 0.95600000 at epoch 63 batch 70\n",
      "validation cost 0.10853309, validation accuracy 0.96740000 at epoch 63, batch 70/110\n",
      "train cost 0.13429548, train accuracy 0.96000000 at epoch 63 batch 90\n",
      "train cost 0.14925763, train accuracy 0.95400000 at epoch 64 batch 0\n",
      "train cost 0.15193321, train accuracy 0.96200000 at epoch 64 batch 20\n",
      "train cost 0.14654170, train accuracy 0.96200000 at epoch 64 batch 40\n",
      "train cost 0.09873269, train accuracy 0.97400000 at epoch 64 batch 60\n",
      "validation cost 0.10313283, validation accuracy 0.96800000 at epoch 64, batch 60/110\n",
      "train cost 0.12689731, train accuracy 0.96200000 at epoch 64 batch 80\n",
      "train cost 0.15725230, train accuracy 0.95200000 at epoch 64 batch 100\n",
      "train cost 0.14165872, train accuracy 0.96000000 at epoch 65 batch 10\n",
      "train cost 0.11704427, train accuracy 0.97000000 at epoch 65 batch 30\n",
      "train cost 0.11963688, train accuracy 0.96000000 at epoch 65 batch 50\n",
      "validation cost 0.10702084, validation accuracy 0.97020000 at epoch 65, batch 50/110\n",
      "train cost 0.11926987, train accuracy 0.96200000 at epoch 65 batch 70\n",
      "train cost 0.13605319, train accuracy 0.95200000 at epoch 65 batch 90\n",
      "train cost 0.10969932, train accuracy 0.96800000 at epoch 66 batch 0\n",
      "train cost 0.15038104, train accuracy 0.95000000 at epoch 66 batch 20\n",
      "train cost 0.15704823, train accuracy 0.95200000 at epoch 66 batch 40\n",
      "validation cost 0.11118510, validation accuracy 0.96800000 at epoch 66, batch 40/110\n",
      "train cost 0.10609019, train accuracy 0.96600000 at epoch 66 batch 60\n",
      "train cost 0.10915855, train accuracy 0.97200000 at epoch 66 batch 80\n",
      "train cost 0.16257294, train accuracy 0.95600000 at epoch 66 batch 100\n",
      "train cost 0.13233399, train accuracy 0.96000000 at epoch 67 batch 10\n",
      "train cost 0.12456838, train accuracy 0.95600000 at epoch 67 batch 30\n",
      "validation cost 0.10978911, validation accuracy 0.96800000 at epoch 67, batch 30/110\n",
      "train cost 0.11423386, train accuracy 0.95600000 at epoch 67 batch 50\n",
      "train cost 0.12416267, train accuracy 0.97000000 at epoch 67 batch 70\n",
      "train cost 0.11330705, train accuracy 0.96400000 at epoch 67 batch 90\n",
      "train cost 0.14821117, train accuracy 0.95200000 at epoch 68 batch 0\n",
      "train cost 0.13626011, train accuracy 0.95800000 at epoch 68 batch 20\n",
      "validation cost 0.10827985, validation accuracy 0.96840000 at epoch 68, batch 20/110\n",
      "train cost 0.12790959, train accuracy 0.96800000 at epoch 68 batch 40\n",
      "train cost 0.10473225, train accuracy 0.96600000 at epoch 68 batch 60\n",
      "train cost 0.12995565, train accuracy 0.96200000 at epoch 68 batch 80\n",
      "train cost 0.16380660, train accuracy 0.95200000 at epoch 68 batch 100\n",
      "train cost 0.13289493, train accuracy 0.97000000 at epoch 69 batch 10\n",
      "validation cost 0.10277793, validation accuracy 0.96880000 at epoch 69, batch 10/110\n",
      "train cost 0.10726082, train accuracy 0.96800000 at epoch 69 batch 30\n",
      "train cost 0.12600198, train accuracy 0.95800000 at epoch 69 batch 50\n",
      "train cost 0.12248629, train accuracy 0.96000000 at epoch 69 batch 70\n",
      "train cost 0.11679646, train accuracy 0.96000000 at epoch 69 batch 90\n",
      "train cost 0.12216897, train accuracy 0.96600000 at epoch 70 batch 0\n",
      "validation cost 0.10623425, validation accuracy 0.96780000 at epoch 70, batch 0/110\n",
      "train cost 0.15174997, train accuracy 0.95800000 at epoch 70 batch 20\n",
      "train cost 0.13101420, train accuracy 0.96800000 at epoch 70 batch 40\n",
      "train cost 0.11401061, train accuracy 0.97400000 at epoch 70 batch 60\n",
      "train cost 0.13931076, train accuracy 0.96200000 at epoch 70 batch 80\n",
      "train cost 0.14648330, train accuracy 0.94400000 at epoch 70 batch 100\n",
      "validation cost 0.10870264, validation accuracy 0.96740000 at epoch 70, batch 100/110\n",
      "train cost 0.11975385, train accuracy 0.97200000 at epoch 71 batch 10\n",
      "train cost 0.09818768, train accuracy 0.97200000 at epoch 71 batch 30\n",
      "train cost 0.10561354, train accuracy 0.96200000 at epoch 71 batch 50\n",
      "train cost 0.11965636, train accuracy 0.97400000 at epoch 71 batch 70\n",
      "train cost 0.12235384, train accuracy 0.97000000 at epoch 71 batch 90\n",
      "validation cost 0.09855872, validation accuracy 0.97280000 at epoch 71, batch 90/110\n",
      "train cost 0.10528781, train accuracy 0.97200000 at epoch 72 batch 0\n",
      "train cost 0.14620319, train accuracy 0.95800000 at epoch 72 batch 20\n",
      "train cost 0.14954035, train accuracy 0.94800000 at epoch 72 batch 40\n",
      "train cost 0.10695856, train accuracy 0.96400000 at epoch 72 batch 60\n",
      "train cost 0.09931188, train accuracy 0.97400000 at epoch 72 batch 80\n",
      "validation cost 0.10699449, validation accuracy 0.97100000 at epoch 72, batch 80/110\n",
      "train cost 0.16152194, train accuracy 0.94200000 at epoch 72 batch 100\n",
      "train cost 0.13702835, train accuracy 0.95600000 at epoch 73 batch 10\n",
      "train cost 0.13782109, train accuracy 0.96400000 at epoch 73 batch 30\n",
      "train cost 0.08899602, train accuracy 0.97400000 at epoch 73 batch 50\n",
      "train cost 0.12134630, train accuracy 0.97000000 at epoch 73 batch 70\n",
      "validation cost 0.10729748, validation accuracy 0.96800000 at epoch 73, batch 70/110\n",
      "train cost 0.11260939, train accuracy 0.96800000 at epoch 73 batch 90\n",
      "train cost 0.09493255, train accuracy 0.97400000 at epoch 74 batch 0\n",
      "train cost 0.14646609, train accuracy 0.96000000 at epoch 74 batch 20\n",
      "train cost 0.13756450, train accuracy 0.96400000 at epoch 74 batch 40\n",
      "train cost 0.10355290, train accuracy 0.96600000 at epoch 74 batch 60\n",
      "validation cost 0.09789364, validation accuracy 0.97280000 at epoch 74, batch 60/110\n",
      "train cost 0.10333361, train accuracy 0.97200000 at epoch 74 batch 80\n",
      "train cost 0.12444315, train accuracy 0.96600000 at epoch 74 batch 100\n",
      "train cost 0.12364156, train accuracy 0.95800000 at epoch 75 batch 10\n",
      "train cost 0.10491960, train accuracy 0.96200000 at epoch 75 batch 30\n",
      "train cost 0.09007066, train accuracy 0.97000000 at epoch 75 batch 50\n",
      "validation cost 0.09664449, validation accuracy 0.97240000 at epoch 75, batch 50/110\n",
      "train cost 0.11431272, train accuracy 0.97200000 at epoch 75 batch 70\n",
      "train cost 0.10868851, train accuracy 0.97000000 at epoch 75 batch 90\n",
      "train cost 0.10636799, train accuracy 0.97200000 at epoch 76 batch 0\n",
      "train cost 0.14067006, train accuracy 0.95000000 at epoch 76 batch 20\n",
      "train cost 0.12699354, train accuracy 0.96200000 at epoch 76 batch 40\n",
      "validation cost 0.10155773, validation accuracy 0.96900000 at epoch 76, batch 40/110\n",
      "train cost 0.09239948, train accuracy 0.97000000 at epoch 76 batch 60\n",
      "train cost 0.12070046, train accuracy 0.96200000 at epoch 76 batch 80\n",
      "train cost 0.12900190, train accuracy 0.95800000 at epoch 76 batch 100\n",
      "train cost 0.10646661, train accuracy 0.96600000 at epoch 77 batch 10\n",
      "train cost 0.10316210, train accuracy 0.97400000 at epoch 77 batch 30\n",
      "validation cost 0.10571862, validation accuracy 0.97100000 at epoch 77, batch 30/110\n",
      "train cost 0.08600012, train accuracy 0.97200000 at epoch 77 batch 50\n",
      "train cost 0.13708939, train accuracy 0.96000000 at epoch 77 batch 70\n",
      "train cost 0.09793469, train accuracy 0.97400000 at epoch 77 batch 90\n",
      "train cost 0.11300408, train accuracy 0.96800000 at epoch 78 batch 0\n",
      "train cost 0.13203956, train accuracy 0.96400000 at epoch 78 batch 20\n",
      "validation cost 0.10456570, validation accuracy 0.97200000 at epoch 78, batch 20/110\n",
      "train cost 0.13286234, train accuracy 0.96200000 at epoch 78 batch 40\n",
      "train cost 0.09375094, train accuracy 0.96800000 at epoch 78 batch 60\n",
      "train cost 0.09074418, train accuracy 0.97000000 at epoch 78 batch 80\n",
      "train cost 0.13229868, train accuracy 0.96000000 at epoch 78 batch 100\n",
      "train cost 0.12588918, train accuracy 0.96600000 at epoch 79 batch 10\n",
      "validation cost 0.10029672, validation accuracy 0.97140000 at epoch 79, batch 10/110\n",
      "train cost 0.11557581, train accuracy 0.96400000 at epoch 79 batch 30\n",
      "train cost 0.11535905, train accuracy 0.96200000 at epoch 79 batch 50\n",
      "train cost 0.13432004, train accuracy 0.96000000 at epoch 79 batch 70\n",
      "train cost 0.11029700, train accuracy 0.96800000 at epoch 79 batch 90\n",
      "train cost 0.10446867, train accuracy 0.96600000 at epoch 80 batch 0\n",
      "validation cost 0.10553804, validation accuracy 0.97120000 at epoch 80, batch 0/110\n",
      "train cost 0.17765111, train accuracy 0.94800000 at epoch 80 batch 20\n",
      "train cost 0.12335844, train accuracy 0.96000000 at epoch 80 batch 40\n",
      "train cost 0.06980965, train accuracy 0.98000000 at epoch 80 batch 60\n",
      "train cost 0.09941439, train accuracy 0.98200000 at epoch 80 batch 80\n",
      "train cost 0.13165979, train accuracy 0.96200000 at epoch 80 batch 100\n",
      "validation cost 0.10282309, validation accuracy 0.97080000 at epoch 80, batch 100/110\n",
      "train cost 0.12789072, train accuracy 0.96000000 at epoch 81 batch 10\n",
      "train cost 0.11993486, train accuracy 0.96000000 at epoch 81 batch 30\n",
      "train cost 0.08037596, train accuracy 0.97400000 at epoch 81 batch 50\n",
      "train cost 0.10525787, train accuracy 0.97000000 at epoch 81 batch 70\n",
      "train cost 0.11038909, train accuracy 0.97200000 at epoch 81 batch 90\n",
      "validation cost 0.09235938, validation accuracy 0.97300000 at epoch 81, batch 90/110\n",
      "train cost 0.10909794, train accuracy 0.96400000 at epoch 82 batch 0\n",
      "train cost 0.14478764, train accuracy 0.94600000 at epoch 82 batch 20\n",
      "train cost 0.12476648, train accuracy 0.96400000 at epoch 82 batch 40\n",
      "train cost 0.09939439, train accuracy 0.97800000 at epoch 82 batch 60\n",
      "train cost 0.14257701, train accuracy 0.95800000 at epoch 82 batch 80\n",
      "validation cost 0.09234004, validation accuracy 0.97220000 at epoch 82, batch 80/110\n",
      "train cost 0.12747313, train accuracy 0.96400000 at epoch 82 batch 100\n",
      "train cost 0.12090219, train accuracy 0.96000000 at epoch 83 batch 10\n",
      "train cost 0.11656168, train accuracy 0.96400000 at epoch 83 batch 30\n",
      "train cost 0.09313793, train accuracy 0.97400000 at epoch 83 batch 50\n",
      "train cost 0.11863323, train accuracy 0.96800000 at epoch 83 batch 70\n",
      "validation cost 0.09169600, validation accuracy 0.97280000 at epoch 83, batch 70/110\n",
      "train cost 0.11809291, train accuracy 0.96600000 at epoch 83 batch 90\n",
      "train cost 0.10140355, train accuracy 0.96800000 at epoch 84 batch 0\n",
      "train cost 0.16277894, train accuracy 0.94800000 at epoch 84 batch 20\n",
      "train cost 0.12225526, train accuracy 0.96200000 at epoch 84 batch 40\n",
      "train cost 0.11361464, train accuracy 0.96400000 at epoch 84 batch 60\n",
      "validation cost 0.10124179, validation accuracy 0.96880000 at epoch 84, batch 60/110\n",
      "train cost 0.09733140, train accuracy 0.96400000 at epoch 84 batch 80\n",
      "train cost 0.13679744, train accuracy 0.97000000 at epoch 84 batch 100\n",
      "train cost 0.12141038, train accuracy 0.96600000 at epoch 85 batch 10\n",
      "train cost 0.09757145, train accuracy 0.97000000 at epoch 85 batch 30\n",
      "train cost 0.08037002, train accuracy 0.97600000 at epoch 85 batch 50\n",
      "validation cost 0.10312245, validation accuracy 0.97140000 at epoch 85, batch 50/110\n",
      "train cost 0.12721108, train accuracy 0.96400000 at epoch 85 batch 70\n",
      "train cost 0.09845375, train accuracy 0.96600000 at epoch 85 batch 90\n",
      "train cost 0.09606198, train accuracy 0.97000000 at epoch 86 batch 0\n",
      "train cost 0.13951424, train accuracy 0.95200000 at epoch 86 batch 20\n",
      "train cost 0.13360871, train accuracy 0.96200000 at epoch 86 batch 40\n",
      "validation cost 0.09336541, validation accuracy 0.97120000 at epoch 86, batch 40/110\n",
      "train cost 0.10406699, train accuracy 0.97000000 at epoch 86 batch 60\n",
      "train cost 0.10429923, train accuracy 0.97600000 at epoch 86 batch 80\n",
      "train cost 0.10797969, train accuracy 0.97200000 at epoch 86 batch 100\n",
      "train cost 0.12612806, train accuracy 0.96200000 at epoch 87 batch 10\n",
      "train cost 0.09303340, train accuracy 0.97200000 at epoch 87 batch 30\n",
      "validation cost 0.09118912, validation accuracy 0.97580000 at epoch 87, batch 30/110\n",
      "train cost 0.08512453, train accuracy 0.97800000 at epoch 87 batch 50\n",
      "train cost 0.10721055, train accuracy 0.97800000 at epoch 87 batch 70\n",
      "train cost 0.09019652, train accuracy 0.97000000 at epoch 87 batch 90\n",
      "train cost 0.10519764, train accuracy 0.96600000 at epoch 88 batch 0\n",
      "train cost 0.15195636, train accuracy 0.95600000 at epoch 88 batch 20\n",
      "validation cost 0.09492942, validation accuracy 0.97340000 at epoch 88, batch 20/110\n",
      "train cost 0.11398224, train accuracy 0.97000000 at epoch 88 batch 40\n",
      "train cost 0.07951357, train accuracy 0.96800000 at epoch 88 batch 60\n",
      "train cost 0.09419672, train accuracy 0.97400000 at epoch 88 batch 80\n",
      "train cost 0.12193687, train accuracy 0.96200000 at epoch 88 batch 100\n",
      "train cost 0.11803024, train accuracy 0.97000000 at epoch 89 batch 10\n",
      "validation cost 0.09455508, validation accuracy 0.97260000 at epoch 89, batch 10/110\n",
      "train cost 0.09395319, train accuracy 0.97600000 at epoch 89 batch 30\n",
      "train cost 0.10376576, train accuracy 0.96200000 at epoch 89 batch 50\n",
      "train cost 0.11001952, train accuracy 0.96800000 at epoch 89 batch 70\n",
      "train cost 0.11578790, train accuracy 0.96000000 at epoch 89 batch 90\n",
      "train cost 0.09199154, train accuracy 0.97400000 at epoch 90 batch 0\n",
      "validation cost 0.09390967, validation accuracy 0.97220000 at epoch 90, batch 0/110\n",
      "train cost 0.12297355, train accuracy 0.96600000 at epoch 90 batch 20\n",
      "train cost 0.09720574, train accuracy 0.97000000 at epoch 90 batch 40\n",
      "train cost 0.10697000, train accuracy 0.97200000 at epoch 90 batch 60\n",
      "train cost 0.08548561, train accuracy 0.97200000 at epoch 90 batch 80\n",
      "train cost 0.13253440, train accuracy 0.96400000 at epoch 90 batch 100\n",
      "validation cost 0.09243519, validation accuracy 0.97240000 at epoch 90, batch 100/110\n",
      "train cost 0.09907079, train accuracy 0.97600000 at epoch 91 batch 10\n",
      "train cost 0.08305755, train accuracy 0.98000000 at epoch 91 batch 30\n",
      "train cost 0.08003101, train accuracy 0.97800000 at epoch 91 batch 50\n",
      "train cost 0.12261483, train accuracy 0.96800000 at epoch 91 batch 70\n",
      "train cost 0.10671250, train accuracy 0.96800000 at epoch 91 batch 90\n",
      "validation cost 0.08922302, validation accuracy 0.97380000 at epoch 91, batch 90/110\n",
      "train cost 0.09618989, train accuracy 0.97000000 at epoch 92 batch 0\n",
      "train cost 0.12497026, train accuracy 0.95800000 at epoch 92 batch 20\n",
      "train cost 0.12503585, train accuracy 0.96800000 at epoch 92 batch 40\n",
      "train cost 0.10437214, train accuracy 0.97000000 at epoch 92 batch 60\n",
      "train cost 0.08800014, train accuracy 0.96600000 at epoch 92 batch 80\n",
      "validation cost 0.09123352, validation accuracy 0.97240000 at epoch 92, batch 80/110\n",
      "train cost 0.13765171, train accuracy 0.95200000 at epoch 92 batch 100\n",
      "train cost 0.11860533, train accuracy 0.96600000 at epoch 93 batch 10\n",
      "train cost 0.08735517, train accuracy 0.97600000 at epoch 93 batch 30\n",
      "train cost 0.08374968, train accuracy 0.97800000 at epoch 93 batch 50\n",
      "train cost 0.09581862, train accuracy 0.97600000 at epoch 93 batch 70\n",
      "validation cost 0.09132291, validation accuracy 0.97400000 at epoch 93, batch 70/110\n",
      "train cost 0.10430489, train accuracy 0.97400000 at epoch 93 batch 90\n",
      "train cost 0.10909235, train accuracy 0.96800000 at epoch 94 batch 0\n",
      "train cost 0.14218354, train accuracy 0.96400000 at epoch 94 batch 20\n",
      "train cost 0.09776240, train accuracy 0.96600000 at epoch 94 batch 40\n",
      "train cost 0.09693401, train accuracy 0.97400000 at epoch 94 batch 60\n",
      "validation cost 0.08838815, validation accuracy 0.97360000 at epoch 94, batch 60/110\n",
      "train cost 0.07873745, train accuracy 0.98000000 at epoch 94 batch 80\n",
      "train cost 0.13317892, train accuracy 0.95000000 at epoch 94 batch 100\n",
      "train cost 0.09805828, train accuracy 0.97600000 at epoch 95 batch 10\n",
      "train cost 0.09756049, train accuracy 0.97200000 at epoch 95 batch 30\n",
      "train cost 0.07479792, train accuracy 0.97400000 at epoch 95 batch 50\n",
      "validation cost 0.09393941, validation accuracy 0.97260000 at epoch 95, batch 50/110\n",
      "train cost 0.10233320, train accuracy 0.97600000 at epoch 95 batch 70\n",
      "train cost 0.10470768, train accuracy 0.96800000 at epoch 95 batch 90\n",
      "train cost 0.12271821, train accuracy 0.96400000 at epoch 96 batch 0\n",
      "train cost 0.13442183, train accuracy 0.94600000 at epoch 96 batch 20\n",
      "train cost 0.11468150, train accuracy 0.96800000 at epoch 96 batch 40\n",
      "validation cost 0.09035463, validation accuracy 0.97460000 at epoch 96, batch 40/110\n",
      "train cost 0.10818982, train accuracy 0.96200000 at epoch 96 batch 60\n",
      "train cost 0.09291653, train accuracy 0.98200000 at epoch 96 batch 80\n",
      "train cost 0.10415596, train accuracy 0.96800000 at epoch 96 batch 100\n",
      "train cost 0.08969363, train accuracy 0.97800000 at epoch 97 batch 10\n",
      "train cost 0.10071326, train accuracy 0.97200000 at epoch 97 batch 30\n",
      "validation cost 0.09169195, validation accuracy 0.97340000 at epoch 97, batch 30/110\n",
      "train cost 0.09563515, train accuracy 0.97200000 at epoch 97 batch 50\n",
      "train cost 0.10880435, train accuracy 0.96400000 at epoch 97 batch 70\n",
      "train cost 0.09811329, train accuracy 0.96800000 at epoch 97 batch 90\n",
      "train cost 0.12859991, train accuracy 0.95600000 at epoch 98 batch 0\n",
      "train cost 0.15026127, train accuracy 0.94800000 at epoch 98 batch 20\n",
      "validation cost 0.09201288, validation accuracy 0.97320000 at epoch 98, batch 20/110\n",
      "train cost 0.11440459, train accuracy 0.96200000 at epoch 98 batch 40\n",
      "train cost 0.07983533, train accuracy 0.97800000 at epoch 98 batch 60\n",
      "train cost 0.10042566, train accuracy 0.97200000 at epoch 98 batch 80\n",
      "train cost 0.12928250, train accuracy 0.96400000 at epoch 98 batch 100\n",
      "train cost 0.11381678, train accuracy 0.96400000 at epoch 99 batch 10\n",
      "validation cost 0.08528325, validation accuracy 0.97360000 at epoch 99, batch 10/110\n",
      "train cost 0.09014310, train accuracy 0.97000000 at epoch 99 batch 30\n",
      "train cost 0.07984310, train accuracy 0.97200000 at epoch 99 batch 50\n",
      "train cost 0.11846723, train accuracy 0.97000000 at epoch 99 batch 70\n",
      "train cost 0.10782985, train accuracy 0.96600000 at epoch 99 batch 90\n",
      "train cost 0.10054182, train accuracy 0.96400000 at epoch 100 batch 0\n",
      "validation cost 0.08671678, validation accuracy 0.97420000 at epoch 100, batch 0/110\n",
      "train cost 0.10878585, train accuracy 0.97200000 at epoch 100 batch 20\n",
      "train cost 0.10989026, train accuracy 0.95800000 at epoch 100 batch 40\n",
      "train cost 0.07339673, train accuracy 0.97800000 at epoch 100 batch 60\n",
      "train cost 0.09156311, train accuracy 0.97600000 at epoch 100 batch 80\n",
      "train cost 0.13459972, train accuracy 0.95800000 at epoch 100 batch 100\n",
      "validation cost 0.09620367, validation accuracy 0.97220000 at epoch 100, batch 100/110\n",
      "train cost 0.10089859, train accuracy 0.97800000 at epoch 101 batch 10\n",
      "train cost 0.09411175, train accuracy 0.97600000 at epoch 101 batch 30\n",
      "train cost 0.08785262, train accuracy 0.97600000 at epoch 101 batch 50\n",
      "train cost 0.10927251, train accuracy 0.97000000 at epoch 101 batch 70\n",
      "train cost 0.08479563, train accuracy 0.96800000 at epoch 101 batch 90\n",
      "validation cost 0.08949453, validation accuracy 0.97380000 at epoch 101, batch 90/110\n",
      "train cost 0.09756936, train accuracy 0.97400000 at epoch 102 batch 0\n",
      "train cost 0.09348084, train accuracy 0.96600000 at epoch 102 batch 20\n",
      "train cost 0.10630953, train accuracy 0.96200000 at epoch 102 batch 40\n",
      "train cost 0.08760717, train accuracy 0.97400000 at epoch 102 batch 60\n",
      "train cost 0.08189563, train accuracy 0.97200000 at epoch 102 batch 80\n",
      "validation cost 0.09146801, validation accuracy 0.97380000 at epoch 102, batch 80/110\n",
      "train cost 0.10875430, train accuracy 0.97000000 at epoch 102 batch 100\n",
      "train cost 0.12575519, train accuracy 0.96200000 at epoch 103 batch 10\n",
      "train cost 0.08760934, train accuracy 0.97600000 at epoch 103 batch 30\n",
      "train cost 0.06598757, train accuracy 0.97800000 at epoch 103 batch 50\n",
      "train cost 0.10137730, train accuracy 0.97200000 at epoch 103 batch 70\n",
      "validation cost 0.09206384, validation accuracy 0.97440000 at epoch 103, batch 70/110\n",
      "train cost 0.10690347, train accuracy 0.97000000 at epoch 103 batch 90\n",
      "train cost 0.10819465, train accuracy 0.97000000 at epoch 104 batch 0\n",
      "train cost 0.11683974, train accuracy 0.96800000 at epoch 104 batch 20\n",
      "train cost 0.10347445, train accuracy 0.96800000 at epoch 104 batch 40\n",
      "train cost 0.07638158, train accuracy 0.98000000 at epoch 104 batch 60\n",
      "validation cost 0.08982239, validation accuracy 0.97280000 at epoch 104, batch 60/110\n",
      "train cost 0.10096031, train accuracy 0.96600000 at epoch 104 batch 80\n",
      "train cost 0.10939694, train accuracy 0.96800000 at epoch 104 batch 100\n",
      "train cost 0.10372010, train accuracy 0.97000000 at epoch 105 batch 10\n",
      "train cost 0.09072596, train accuracy 0.96800000 at epoch 105 batch 30\n",
      "train cost 0.06607571, train accuracy 0.98200000 at epoch 105 batch 50\n",
      "validation cost 0.09032569, validation accuracy 0.97480000 at epoch 105, batch 50/110\n",
      "train cost 0.11629912, train accuracy 0.97200000 at epoch 105 batch 70\n",
      "train cost 0.12354265, train accuracy 0.96200000 at epoch 105 batch 90\n",
      "train cost 0.10605072, train accuracy 0.97600000 at epoch 106 batch 0\n",
      "train cost 0.10419793, train accuracy 0.97400000 at epoch 106 batch 20\n",
      "train cost 0.10944559, train accuracy 0.96800000 at epoch 106 batch 40\n",
      "validation cost 0.08155035, validation accuracy 0.97720000 at epoch 106, batch 40/110\n",
      "train cost 0.08013432, train accuracy 0.98200000 at epoch 106 batch 60\n",
      "train cost 0.09101592, train accuracy 0.97000000 at epoch 106 batch 80\n",
      "train cost 0.11319788, train accuracy 0.96600000 at epoch 106 batch 100\n",
      "train cost 0.10180482, train accuracy 0.96600000 at epoch 107 batch 10\n",
      "train cost 0.07743739, train accuracy 0.97800000 at epoch 107 batch 30\n",
      "validation cost 0.08882375, validation accuracy 0.97240000 at epoch 107, batch 30/110\n",
      "train cost 0.08016090, train accuracy 0.97400000 at epoch 107 batch 50\n",
      "train cost 0.12181617, train accuracy 0.96800000 at epoch 107 batch 70\n",
      "train cost 0.08550268, train accuracy 0.97600000 at epoch 107 batch 90\n",
      "train cost 0.08719639, train accuracy 0.97200000 at epoch 108 batch 0\n",
      "train cost 0.11060036, train accuracy 0.97600000 at epoch 108 batch 20\n",
      "validation cost 0.08714153, validation accuracy 0.97380000 at epoch 108, batch 20/110\n",
      "train cost 0.10385354, train accuracy 0.96400000 at epoch 108 batch 40\n",
      "train cost 0.08370714, train accuracy 0.97800000 at epoch 108 batch 60\n",
      "train cost 0.08694442, train accuracy 0.97200000 at epoch 108 batch 80\n",
      "train cost 0.09703720, train accuracy 0.97000000 at epoch 108 batch 100\n",
      "train cost 0.12329085, train accuracy 0.97000000 at epoch 109 batch 10\n",
      "validation cost 0.08273293, validation accuracy 0.97380000 at epoch 109, batch 10/110\n",
      "train cost 0.07816719, train accuracy 0.97800000 at epoch 109 batch 30\n",
      "train cost 0.07206880, train accuracy 0.98200000 at epoch 109 batch 50\n",
      "train cost 0.11108717, train accuracy 0.96200000 at epoch 109 batch 70\n",
      "train cost 0.09557317, train accuracy 0.96600000 at epoch 109 batch 90\n",
      "train cost 0.09469064, train accuracy 0.97000000 at epoch 110 batch 0\n",
      "validation cost 0.08624949, validation accuracy 0.97440000 at epoch 110, batch 0/110\n",
      "train cost 0.12594631, train accuracy 0.95200000 at epoch 110 batch 20\n",
      "train cost 0.11244993, train accuracy 0.96600000 at epoch 110 batch 40\n",
      "train cost 0.08510647, train accuracy 0.97600000 at epoch 110 batch 60\n",
      "train cost 0.08969617, train accuracy 0.97000000 at epoch 110 batch 80\n",
      "train cost 0.10834391, train accuracy 0.97600000 at epoch 110 batch 100\n",
      "validation cost 0.08713646, validation accuracy 0.97400000 at epoch 110, batch 100/110\n",
      "train cost 0.11175821, train accuracy 0.96600000 at epoch 111 batch 10\n",
      "train cost 0.09438964, train accuracy 0.97200000 at epoch 111 batch 30\n",
      "train cost 0.06272919, train accuracy 0.97600000 at epoch 111 batch 50\n",
      "train cost 0.11581343, train accuracy 0.97000000 at epoch 111 batch 70\n",
      "train cost 0.11150034, train accuracy 0.95400000 at epoch 111 batch 90\n",
      "validation cost 0.08277359, validation accuracy 0.97480000 at epoch 111, batch 90/110\n",
      "train cost 0.10789941, train accuracy 0.97000000 at epoch 112 batch 0\n",
      "train cost 0.11336020, train accuracy 0.96800000 at epoch 112 batch 20\n",
      "train cost 0.10325753, train accuracy 0.96800000 at epoch 112 batch 40\n",
      "train cost 0.08546960, train accuracy 0.97600000 at epoch 112 batch 60\n",
      "train cost 0.06459282, train accuracy 0.97800000 at epoch 112 batch 80\n",
      "validation cost 0.09144638, validation accuracy 0.97260000 at epoch 112, batch 80/110\n",
      "train cost 0.10669512, train accuracy 0.97200000 at epoch 112 batch 100\n",
      "train cost 0.11503812, train accuracy 0.96600000 at epoch 113 batch 10\n",
      "train cost 0.08077741, train accuracy 0.98200000 at epoch 113 batch 30\n",
      "train cost 0.08778383, train accuracy 0.96800000 at epoch 113 batch 50\n",
      "train cost 0.10838180, train accuracy 0.97400000 at epoch 113 batch 70\n",
      "validation cost 0.08466922, validation accuracy 0.97500000 at epoch 113, batch 70/110\n",
      "train cost 0.08470095, train accuracy 0.97200000 at epoch 113 batch 90\n",
      "train cost 0.12369516, train accuracy 0.96200000 at epoch 114 batch 0\n",
      "train cost 0.10590152, train accuracy 0.97600000 at epoch 114 batch 20\n",
      "train cost 0.10568105, train accuracy 0.96800000 at epoch 114 batch 40\n",
      "train cost 0.08118319, train accuracy 0.97600000 at epoch 114 batch 60\n",
      "validation cost 0.08374699, validation accuracy 0.97760000 at epoch 114, batch 60/110\n",
      "train cost 0.08945912, train accuracy 0.97600000 at epoch 114 batch 80\n",
      "train cost 0.10172792, train accuracy 0.97000000 at epoch 114 batch 100\n",
      "train cost 0.11339410, train accuracy 0.96400000 at epoch 115 batch 10\n",
      "train cost 0.10765012, train accuracy 0.96400000 at epoch 115 batch 30\n",
      "train cost 0.07253024, train accuracy 0.97600000 at epoch 115 batch 50\n",
      "validation cost 0.08203747, validation accuracy 0.97520000 at epoch 115, batch 50/110\n",
      "train cost 0.10244228, train accuracy 0.96800000 at epoch 115 batch 70\n",
      "train cost 0.11104678, train accuracy 0.97000000 at epoch 115 batch 90\n",
      "train cost 0.09806292, train accuracy 0.97200000 at epoch 116 batch 0\n",
      "train cost 0.08724755, train accuracy 0.97400000 at epoch 116 batch 20\n",
      "train cost 0.10207549, train accuracy 0.96800000 at epoch 116 batch 40\n",
      "validation cost 0.08690677, validation accuracy 0.97400000 at epoch 116, batch 40/110\n",
      "train cost 0.09138983, train accuracy 0.97200000 at epoch 116 batch 60\n",
      "train cost 0.09317765, train accuracy 0.97200000 at epoch 116 batch 80\n",
      "train cost 0.13431965, train accuracy 0.95800000 at epoch 116 batch 100\n",
      "train cost 0.11587926, train accuracy 0.96600000 at epoch 117 batch 10\n",
      "train cost 0.07633555, train accuracy 0.97800000 at epoch 117 batch 30\n",
      "validation cost 0.08923194, validation accuracy 0.97340000 at epoch 117, batch 30/110\n",
      "train cost 0.08906174, train accuracy 0.96600000 at epoch 117 batch 50\n",
      "train cost 0.13203628, train accuracy 0.96600000 at epoch 117 batch 70\n",
      "train cost 0.09945045, train accuracy 0.97000000 at epoch 117 batch 90\n",
      "train cost 0.08232922, train accuracy 0.96800000 at epoch 118 batch 0\n",
      "train cost 0.11569296, train accuracy 0.96000000 at epoch 118 batch 20\n",
      "validation cost 0.08190902, validation accuracy 0.97740000 at epoch 118, batch 20/110\n",
      "train cost 0.11309383, train accuracy 0.96800000 at epoch 118 batch 40\n",
      "train cost 0.08544040, train accuracy 0.97800000 at epoch 118 batch 60\n",
      "train cost 0.08362398, train accuracy 0.97000000 at epoch 118 batch 80\n",
      "train cost 0.12236281, train accuracy 0.96400000 at epoch 118 batch 100\n",
      "train cost 0.10701188, train accuracy 0.97000000 at epoch 119 batch 10\n",
      "validation cost 0.08298671, validation accuracy 0.97760000 at epoch 119, batch 10/110\n",
      "train cost 0.10039531, train accuracy 0.96600000 at epoch 119 batch 30\n",
      "train cost 0.07991882, train accuracy 0.97800000 at epoch 119 batch 50\n",
      "train cost 0.08728237, train accuracy 0.97600000 at epoch 119 batch 70\n",
      "train cost 0.08915135, train accuracy 0.97200000 at epoch 119 batch 90\n",
      "train cost 0.10005590, train accuracy 0.97000000 at epoch 120 batch 0\n",
      "validation cost 0.08673244, validation accuracy 0.97420000 at epoch 120, batch 0/110\n",
      "train cost 0.09571451, train accuracy 0.97400000 at epoch 120 batch 20\n",
      "train cost 0.09186143, train accuracy 0.97200000 at epoch 120 batch 40\n",
      "train cost 0.11544527, train accuracy 0.96200000 at epoch 120 batch 60\n",
      "train cost 0.10208376, train accuracy 0.97200000 at epoch 120 batch 80\n",
      "train cost 0.12247260, train accuracy 0.96600000 at epoch 120 batch 100\n",
      "validation cost 0.07985239, validation accuracy 0.97700000 at epoch 120, batch 100/110\n",
      "train cost 0.09856068, train accuracy 0.97400000 at epoch 121 batch 10\n",
      "train cost 0.07589136, train accuracy 0.98000000 at epoch 121 batch 30\n",
      "train cost 0.06147149, train accuracy 0.98400000 at epoch 121 batch 50\n",
      "train cost 0.09487870, train accuracy 0.96800000 at epoch 121 batch 70\n",
      "train cost 0.09296450, train accuracy 0.96800000 at epoch 121 batch 90\n",
      "validation cost 0.08780238, validation accuracy 0.97380000 at epoch 121, batch 90/110\n",
      "train cost 0.06426027, train accuracy 0.98200000 at epoch 122 batch 0\n",
      "train cost 0.13624135, train accuracy 0.96600000 at epoch 122 batch 20\n",
      "train cost 0.10066004, train accuracy 0.96400000 at epoch 122 batch 40\n",
      "train cost 0.08203043, train accuracy 0.97600000 at epoch 122 batch 60\n",
      "train cost 0.08186420, train accuracy 0.97400000 at epoch 122 batch 80\n",
      "validation cost 0.08821671, validation accuracy 0.97380000 at epoch 122, batch 80/110\n",
      "train cost 0.08720949, train accuracy 0.98000000 at epoch 122 batch 100\n",
      "train cost 0.11631539, train accuracy 0.96600000 at epoch 123 batch 10\n",
      "train cost 0.08827095, train accuracy 0.96800000 at epoch 123 batch 30\n",
      "train cost 0.06722042, train accuracy 0.98200000 at epoch 123 batch 50\n",
      "train cost 0.10107665, train accuracy 0.97200000 at epoch 123 batch 70\n",
      "validation cost 0.08239985, validation accuracy 0.97360000 at epoch 123, batch 70/110\n",
      "train cost 0.09341045, train accuracy 0.96800000 at epoch 123 batch 90\n",
      "train cost 0.09964133, train accuracy 0.97400000 at epoch 124 batch 0\n",
      "train cost 0.11509082, train accuracy 0.96600000 at epoch 124 batch 20\n",
      "train cost 0.09917434, train accuracy 0.97400000 at epoch 124 batch 40\n",
      "train cost 0.09731864, train accuracy 0.97200000 at epoch 124 batch 60\n",
      "validation cost 0.08142145, validation accuracy 0.97340000 at epoch 124, batch 60/110\n",
      "train cost 0.09131350, train accuracy 0.97200000 at epoch 124 batch 80\n",
      "train cost 0.10204446, train accuracy 0.96600000 at epoch 124 batch 100\n",
      "train cost 0.09911025, train accuracy 0.97600000 at epoch 125 batch 10\n",
      "train cost 0.08649706, train accuracy 0.97800000 at epoch 125 batch 30\n",
      "train cost 0.05070948, train accuracy 0.98400000 at epoch 125 batch 50\n",
      "validation cost 0.08173480, validation accuracy 0.97520000 at epoch 125, batch 50/110\n",
      "train cost 0.10516163, train accuracy 0.97400000 at epoch 125 batch 70\n",
      "train cost 0.10484733, train accuracy 0.96200000 at epoch 125 batch 90\n",
      "train cost 0.08339838, train accuracy 0.97000000 at epoch 126 batch 0\n",
      "train cost 0.10762316, train accuracy 0.96000000 at epoch 126 batch 20\n",
      "train cost 0.10377866, train accuracy 0.95800000 at epoch 126 batch 40\n",
      "validation cost 0.07458620, validation accuracy 0.97580000 at epoch 126, batch 40/110\n",
      "train cost 0.06333694, train accuracy 0.98600000 at epoch 126 batch 60\n",
      "train cost 0.06451689, train accuracy 0.97800000 at epoch 126 batch 80\n",
      "train cost 0.10955263, train accuracy 0.96400000 at epoch 126 batch 100\n",
      "train cost 0.10739129, train accuracy 0.96400000 at epoch 127 batch 10\n",
      "train cost 0.08200808, train accuracy 0.97000000 at epoch 127 batch 30\n",
      "validation cost 0.08091660, validation accuracy 0.97520000 at epoch 127, batch 30/110\n",
      "train cost 0.07666700, train accuracy 0.97000000 at epoch 127 batch 50\n",
      "train cost 0.09387495, train accuracy 0.97400000 at epoch 127 batch 70\n",
      "train cost 0.09515348, train accuracy 0.97000000 at epoch 127 batch 90\n",
      "train cost 0.07460736, train accuracy 0.97400000 at epoch 128 batch 0\n",
      "train cost 0.11844793, train accuracy 0.96200000 at epoch 128 batch 20\n",
      "validation cost 0.08386356, validation accuracy 0.97520000 at epoch 128, batch 20/110\n",
      "train cost 0.11741111, train accuracy 0.96600000 at epoch 128 batch 40\n",
      "train cost 0.08299030, train accuracy 0.97600000 at epoch 128 batch 60\n",
      "train cost 0.06753142, train accuracy 0.98000000 at epoch 128 batch 80\n",
      "train cost 0.11402167, train accuracy 0.96400000 at epoch 128 batch 100\n",
      "train cost 0.09628323, train accuracy 0.97600000 at epoch 129 batch 10\n",
      "validation cost 0.07825376, validation accuracy 0.97560000 at epoch 129, batch 10/110\n",
      "train cost 0.09219702, train accuracy 0.97000000 at epoch 129 batch 30\n",
      "train cost 0.06537586, train accuracy 0.97800000 at epoch 129 batch 50\n",
      "train cost 0.09534369, train accuracy 0.97000000 at epoch 129 batch 70\n",
      "train cost 0.08205295, train accuracy 0.98000000 at epoch 129 batch 90\n",
      "train cost 0.10349562, train accuracy 0.97200000 at epoch 130 batch 0\n",
      "validation cost 0.08180504, validation accuracy 0.97600000 at epoch 130, batch 0/110\n",
      "train cost 0.10744373, train accuracy 0.96600000 at epoch 130 batch 20\n",
      "train cost 0.12283068, train accuracy 0.96800000 at epoch 130 batch 40\n",
      "train cost 0.09637412, train accuracy 0.97400000 at epoch 130 batch 60\n",
      "train cost 0.08012894, train accuracy 0.98000000 at epoch 130 batch 80\n",
      "train cost 0.08695072, train accuracy 0.97600000 at epoch 130 batch 100\n",
      "validation cost 0.08129927, validation accuracy 0.97720000 at epoch 130, batch 100/110\n",
      "train cost 0.10657109, train accuracy 0.97200000 at epoch 131 batch 10\n",
      "train cost 0.08547525, train accuracy 0.97000000 at epoch 131 batch 30\n",
      "train cost 0.09604686, train accuracy 0.96200000 at epoch 131 batch 50\n",
      "train cost 0.08168967, train accuracy 0.98200000 at epoch 131 batch 70\n",
      "train cost 0.08007642, train accuracy 0.97600000 at epoch 131 batch 90\n",
      "validation cost 0.07860789, validation accuracy 0.97780000 at epoch 131, batch 90/110\n",
      "train cost 0.09747919, train accuracy 0.97600000 at epoch 132 batch 0\n",
      "train cost 0.08977571, train accuracy 0.97400000 at epoch 132 batch 20\n",
      "train cost 0.10192332, train accuracy 0.96400000 at epoch 132 batch 40\n",
      "train cost 0.07846541, train accuracy 0.97600000 at epoch 132 batch 60\n",
      "train cost 0.08437471, train accuracy 0.97800000 at epoch 132 batch 80\n",
      "validation cost 0.07357543, validation accuracy 0.97580000 at epoch 132, batch 80/110\n",
      "train cost 0.10399427, train accuracy 0.96800000 at epoch 132 batch 100\n",
      "train cost 0.09503530, train accuracy 0.97000000 at epoch 133 batch 10\n",
      "train cost 0.09170581, train accuracy 0.97200000 at epoch 133 batch 30\n",
      "train cost 0.06878912, train accuracy 0.97800000 at epoch 133 batch 50\n",
      "train cost 0.09688843, train accuracy 0.97600000 at epoch 133 batch 70\n",
      "validation cost 0.08914228, validation accuracy 0.97460000 at epoch 133, batch 70/110\n",
      "train cost 0.08160125, train accuracy 0.97800000 at epoch 133 batch 90\n",
      "train cost 0.08520792, train accuracy 0.97600000 at epoch 134 batch 0\n",
      "train cost 0.11197006, train accuracy 0.96400000 at epoch 134 batch 20\n",
      "train cost 0.08493888, train accuracy 0.97200000 at epoch 134 batch 40\n",
      "train cost 0.05958882, train accuracy 0.98400000 at epoch 134 batch 60\n",
      "validation cost 0.07230229, validation accuracy 0.97780000 at epoch 134, batch 60/110\n",
      "train cost 0.08141101, train accuracy 0.98000000 at epoch 134 batch 80\n",
      "train cost 0.09798468, train accuracy 0.96800000 at epoch 134 batch 100\n",
      "train cost 0.09759923, train accuracy 0.97400000 at epoch 135 batch 10\n",
      "train cost 0.06848101, train accuracy 0.97800000 at epoch 135 batch 30\n",
      "train cost 0.06537354, train accuracy 0.97800000 at epoch 135 batch 50\n",
      "validation cost 0.08187652, validation accuracy 0.97220000 at epoch 135, batch 50/110\n",
      "train cost 0.11866399, train accuracy 0.96800000 at epoch 135 batch 70\n",
      "train cost 0.08166748, train accuracy 0.97400000 at epoch 135 batch 90\n",
      "train cost 0.06713485, train accuracy 0.98800000 at epoch 136 batch 0\n",
      "train cost 0.13262697, train accuracy 0.95800000 at epoch 136 batch 20\n",
      "train cost 0.12219703, train accuracy 0.96200000 at epoch 136 batch 40\n",
      "validation cost 0.07453354, validation accuracy 0.97840000 at epoch 136, batch 40/110\n",
      "train cost 0.09205461, train accuracy 0.97600000 at epoch 136 batch 60\n",
      "train cost 0.08680220, train accuracy 0.97600000 at epoch 136 batch 80\n",
      "train cost 0.10605724, train accuracy 0.96400000 at epoch 136 batch 100\n",
      "train cost 0.10129037, train accuracy 0.97200000 at epoch 137 batch 10\n",
      "train cost 0.07780820, train accuracy 0.97000000 at epoch 137 batch 30\n",
      "validation cost 0.08609036, validation accuracy 0.97460000 at epoch 137, batch 30/110\n",
      "train cost 0.06290658, train accuracy 0.97600000 at epoch 137 batch 50\n",
      "train cost 0.08080672, train accuracy 0.98200000 at epoch 137 batch 70\n",
      "train cost 0.08777518, train accuracy 0.97400000 at epoch 137 batch 90\n",
      "train cost 0.07648363, train accuracy 0.98400000 at epoch 138 batch 0\n",
      "train cost 0.11430319, train accuracy 0.96600000 at epoch 138 batch 20\n",
      "validation cost 0.07698812, validation accuracy 0.97620000 at epoch 138, batch 20/110\n",
      "train cost 0.10974871, train accuracy 0.96800000 at epoch 138 batch 40\n",
      "train cost 0.07418113, train accuracy 0.98200000 at epoch 138 batch 60\n",
      "train cost 0.06577642, train accuracy 0.97800000 at epoch 138 batch 80\n",
      "train cost 0.09355243, train accuracy 0.97200000 at epoch 138 batch 100\n",
      "train cost 0.09459830, train accuracy 0.97400000 at epoch 139 batch 10\n",
      "validation cost 0.07747733, validation accuracy 0.97840000 at epoch 139, batch 10/110\n",
      "train cost 0.05841509, train accuracy 0.98000000 at epoch 139 batch 30\n",
      "train cost 0.07506677, train accuracy 0.97400000 at epoch 139 batch 50\n",
      "train cost 0.09359765, train accuracy 0.97400000 at epoch 139 batch 70\n",
      "train cost 0.07349082, train accuracy 0.98200000 at epoch 139 batch 90\n",
      "train cost 0.10537787, train accuracy 0.97400000 at epoch 140 batch 0\n",
      "validation cost 0.08517415, validation accuracy 0.97580000 at epoch 140, batch 0/110\n",
      "train cost 0.10130970, train accuracy 0.97000000 at epoch 140 batch 20\n",
      "train cost 0.10799491, train accuracy 0.97000000 at epoch 140 batch 40\n",
      "train cost 0.09254368, train accuracy 0.95800000 at epoch 140 batch 60\n",
      "train cost 0.06053198, train accuracy 0.98000000 at epoch 140 batch 80\n",
      "train cost 0.09046616, train accuracy 0.97400000 at epoch 140 batch 100\n",
      "validation cost 0.08366719, validation accuracy 0.97520000 at epoch 140, batch 100/110\n",
      "train cost 0.09146281, train accuracy 0.97400000 at epoch 141 batch 10\n",
      "train cost 0.06717947, train accuracy 0.98600000 at epoch 141 batch 30\n",
      "train cost 0.08549491, train accuracy 0.97000000 at epoch 141 batch 50\n",
      "train cost 0.09686413, train accuracy 0.97200000 at epoch 141 batch 70\n",
      "train cost 0.08586205, train accuracy 0.96400000 at epoch 141 batch 90\n",
      "validation cost 0.07848086, validation accuracy 0.97720000 at epoch 141, batch 90/110\n",
      "train cost 0.07794642, train accuracy 0.97400000 at epoch 142 batch 0\n",
      "train cost 0.10936846, train accuracy 0.96600000 at epoch 142 batch 20\n",
      "train cost 0.10191762, train accuracy 0.96800000 at epoch 142 batch 40\n",
      "train cost 0.07019128, train accuracy 0.97400000 at epoch 142 batch 60\n",
      "train cost 0.08404963, train accuracy 0.97600000 at epoch 142 batch 80\n",
      "validation cost 0.08218285, validation accuracy 0.97520000 at epoch 142, batch 80/110\n",
      "train cost 0.10096601, train accuracy 0.97200000 at epoch 142 batch 100\n",
      "train cost 0.10080569, train accuracy 0.97400000 at epoch 143 batch 10\n",
      "train cost 0.06926326, train accuracy 0.97600000 at epoch 143 batch 30\n",
      "train cost 0.08164226, train accuracy 0.97000000 at epoch 143 batch 50\n",
      "train cost 0.09122024, train accuracy 0.98000000 at epoch 143 batch 70\n",
      "validation cost 0.07851885, validation accuracy 0.97720000 at epoch 143, batch 70/110\n",
      "train cost 0.06669783, train accuracy 0.98400000 at epoch 143 batch 90\n",
      "train cost 0.08896018, train accuracy 0.96600000 at epoch 144 batch 0\n",
      "train cost 0.10910977, train accuracy 0.96600000 at epoch 144 batch 20\n",
      "train cost 0.09910338, train accuracy 0.97200000 at epoch 144 batch 40\n",
      "train cost 0.06868938, train accuracy 0.98400000 at epoch 144 batch 60\n",
      "validation cost 0.07963287, validation accuracy 0.97760000 at epoch 144, batch 60/110\n",
      "train cost 0.08170366, train accuracy 0.97600000 at epoch 144 batch 80\n",
      "train cost 0.09027913, train accuracy 0.98200000 at epoch 144 batch 100\n",
      "train cost 0.11080331, train accuracy 0.97000000 at epoch 145 batch 10\n",
      "train cost 0.06673253, train accuracy 0.98000000 at epoch 145 batch 30\n",
      "train cost 0.05117251, train accuracy 0.99200000 at epoch 145 batch 50\n",
      "validation cost 0.08384260, validation accuracy 0.97540000 at epoch 145, batch 50/110\n",
      "train cost 0.08378846, train accuracy 0.97800000 at epoch 145 batch 70\n",
      "train cost 0.08543839, train accuracy 0.97600000 at epoch 145 batch 90\n",
      "train cost 0.07001216, train accuracy 0.98000000 at epoch 146 batch 0\n",
      "train cost 0.11246126, train accuracy 0.95400000 at epoch 146 batch 20\n",
      "train cost 0.12020624, train accuracy 0.96400000 at epoch 146 batch 40\n",
      "validation cost 0.07444184, validation accuracy 0.97640000 at epoch 146, batch 40/110\n",
      "train cost 0.06894652, train accuracy 0.97600000 at epoch 146 batch 60\n",
      "train cost 0.09326696, train accuracy 0.97800000 at epoch 146 batch 80\n",
      "train cost 0.10699280, train accuracy 0.97000000 at epoch 146 batch 100\n",
      "train cost 0.09456768, train accuracy 0.97600000 at epoch 147 batch 10\n",
      "train cost 0.09162994, train accuracy 0.97400000 at epoch 147 batch 30\n",
      "validation cost 0.07841527, validation accuracy 0.97620000 at epoch 147, batch 30/110\n",
      "train cost 0.08612772, train accuracy 0.97600000 at epoch 147 batch 50\n",
      "train cost 0.09938443, train accuracy 0.97400000 at epoch 147 batch 70\n",
      "train cost 0.09086068, train accuracy 0.97200000 at epoch 147 batch 90\n",
      "train cost 0.06740305, train accuracy 0.98200000 at epoch 148 batch 0\n",
      "train cost 0.10898144, train accuracy 0.96000000 at epoch 148 batch 20\n",
      "validation cost 0.07811400, validation accuracy 0.97600000 at epoch 148, batch 20/110\n",
      "train cost 0.07956197, train accuracy 0.97800000 at epoch 148 batch 40\n",
      "train cost 0.06319186, train accuracy 0.98200000 at epoch 148 batch 60\n",
      "train cost 0.08255135, train accuracy 0.97600000 at epoch 148 batch 80\n",
      "train cost 0.09817417, train accuracy 0.97000000 at epoch 148 batch 100\n",
      "train cost 0.09732409, train accuracy 0.97200000 at epoch 149 batch 10\n",
      "validation cost 0.08081544, validation accuracy 0.97540000 at epoch 149, batch 10/110\n",
      "train cost 0.07966512, train accuracy 0.96600000 at epoch 149 batch 30\n",
      "train cost 0.05990792, train accuracy 0.97800000 at epoch 149 batch 50\n",
      "train cost 0.10102884, train accuracy 0.96800000 at epoch 149 batch 70\n",
      "train cost 0.06658413, train accuracy 0.97600000 at epoch 149 batch 90\n",
      "Time Eplapsed 823.5531645779993\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for cur_batch in range(n_batches):\n",
    "        cur_iter = cur_batch + n_batches * epoch\n",
    "        train_cost, train_acc, P = cnn_train_model(cur_batch)\n",
    "        \n",
    "        train_cost_hist.append(train_cost)\n",
    "        train_acc_hist.append(train_acc)\n",
    "        train_prob_hist.append(P)\n",
    "        \n",
    "        if (cur_iter % 20 == 0):\n",
    "            print(\"train cost {:.8f}, train accuracy {:.8f} at epoch {} batch {}\".format(\n",
    "                    train_cost, train_acc, epoch, cur_batch))\n",
    "        if cur_iter % validation_interval == 0:\n",
    "            cur_val = cur_iter // validation_interval\n",
    "            validate_cost, validate_acc = np.mean(\n",
    "                [\n",
    "                cnn_validation_model(\n",
    "                x_validate[i * batch_size: (i+1)*batch_size],\n",
    "                y_validate[i * batch_size: (i+1)*batch_size]\n",
    "            ) for i in range(validate_n_batches)]\n",
    "                , axis=0)\n",
    "            \n",
    "            validate_cost_hist.append(validate_cost)\n",
    "            validate_acc_hist.append(validate_acc)\n",
    "            \n",
    "            print(\"validation cost {:.8f}, validation accuracy {:.8f}\"\n",
    "                  \" at epoch {}, batch {}/{}\".format(validate_cost,\n",
    "                                                    validate_acc,\n",
    "                                                    epoch, cur_batch, n_batches))\n",
    "    \n",
    "stop_time = timeit.default_timer()\n",
    "\n",
    "print(\"Time Eplapsed\", stop_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9755\n"
     ]
    }
   ],
   "source": [
    "test_accs = np.mean([accu.eval({x: x_test[i*batch_size: (i+1)*batch_size],\n",
    "                              t: y_test[i*batch_size: (i+1)*batch_size]})\n",
    "            for i in range(x_test.shape[0] // batch_size)])\n",
    "    \n",
    "print(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(np.arange(len(train_cost_hist)), train_cost_hist)\n",
    "plt.plot(np.arange(len(validate_cost_hist))*validation_interval, validate_cost_hist)\n",
    "plt.legend(['Training cost', 'validation cost'])\n",
    "plt.savefig('Adagrad_cost.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(np.arange(len(train_acc_hist)), train_acc_hist)\n",
    "\n",
    "plt.plot(np.arange(len(validate_acc_hist))*validation_interval,\n",
    "         validate_acc_hist)\n",
    "plt.legend(['Training accuracy', 'validation accuracy'])\n",
    "plt.savefig('Adagrad_acc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(cnn_predict(x_test[:batch_size]), y_test[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.misc.pkl_utils as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnn_params.zip', 'wb') as f:\n",
    "    pkl.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bitb58e4721ed3d4c2a830201a5fb21f5f7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}