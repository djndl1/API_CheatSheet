{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano as th\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionEstimator:\n",
    "    def __init__(self, n_input, n_output):\n",
    "        self.input_shape = n_input\n",
    "        self.output_shape = n_output\n",
    "        \n",
    "        self.weight = th.shared(value=np.asarray(\n",
    "                                np.random.randn(n_input, n_output),\n",
    "                                dtype=th.config.floatX), name='weight', \n",
    "                               borrow=True)\n",
    "        self.bias = th.shared(value=np.zeros((n_output, ), dtype=th.config.floatX),\n",
    "                             name='bias', borrow=True)\n",
    "        self.params = [self.weight, self.bias]\n",
    "        \n",
    "        self.input = T.matrix('x')\n",
    "        self.target = T.ivector('t')\n",
    "        \n",
    "        self.prob = T.nnet.softmax(T.dot(self.input, self.weight) + self.bias)\n",
    "        self.pred = T.argmax(self.prob, axis=1)\n",
    "        \n",
    "        self.loss = -T.mean(T.log(self.prob[T.arange(self.target.shape[0]), self.target]))\n",
    "        self.gparams = T.grad(cost=self.loss, wrt=self.params)\n",
    "        self.accuracy = T.mean(T.eq(self.pred, self.target))\n",
    "        self.predictor = th.function(inputs=[self.input],\n",
    "                                    outputs=[self.pred])\n",
    "              \n",
    "    def fit(self, x, y, epoch, learning_rate, show_intermediate=False):\n",
    "        self.updates = []\n",
    "        for param, gparam in zip(self.params, self.gparams):\n",
    "            param_new = param - learning_rate * gparam\n",
    "            self.updates.append((param, param_new))\n",
    "            \n",
    "        self.estimator = th.function(inputs=[self.input, self.target],\n",
    "                                    outputs=[self.loss, self.accuracy],\n",
    "                                    updates=self.updates)\n",
    "        train_hist = {\n",
    "            'train_acc': [],\n",
    "            'train_loss': []\n",
    "        }\n",
    "        \n",
    "        import timeit\n",
    "        start_time = timeit.default_timer()\n",
    "        for cur_epoch in range(epoch):\n",
    "            loss, acc = self.estimator(x, y)\n",
    "            train_hist['train_acc'].append(acc)\n",
    "            train_hist['train_loss'].append(loss)\n",
    "            \n",
    "            if (cur_epoch + 1) % (epoch / 50) and show_intermediate:\n",
    "                print('Loss: {}, Accuracy: {}'.format(loss, acc))\n",
    "                \n",
    "        end_time = timeit.default_timer()\n",
    "        print('Loss: {}, Accuracy: {}, time elapsed {}'.format(train_hist['train_acc'][-1],\n",
    "                                                              train_hist['train_loss'][-1],\n",
    "                                                              end_time - start_time))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.predictor(x)\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        return self.estimator(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                         np.prod(x_train.shape[1:]))\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                         np.prod(x_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_classifier = LogisticRegressionEstimator(np.prod(x_train.shape[1:]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9290666666666667, Accuracy: 37.7731819152832, time elapsed 1720.5492778560001\n"
     ]
    }
   ],
   "source": [
    "logit_classifier.fit(x_train, y_train, learning_rate=0.01, epoch=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(55.130314, dtype=float32), array(0.9163)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_classifier.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7, 2, 1, 0, 4, 1, 4, 9, 6, 9])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_classifier.predict(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=uint8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import theano_utils\n",
    "from keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "t = T.ivector('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "x_input = x.reshape((batch_size, 1) + x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = theano_utils.conv_layer(x_input, input_shape=(batch_size, 1) + x_train[0].shape,\n",
    "                               filter_shape=(5, 5), n_filters=32)\n",
    "conv1_out = conv1()\n",
    "conv1_pooled = T.signal.pool.pool_2d(input=conv1_out, ws=(2, 2), ignore_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = theano_utils.conv_layer(conv1_pooled, input_shape=(batch_size, 1) + (12, 12),\n",
    "                               filter_shape=(5, 5), n_filters=64)\n",
    "conv2_out = conv2()\n",
    "conv2_pooled = T.signal.pool.pool_2d(input=conv2_out, ws=(2, 2), ignore_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = conv2_pooled.flatten(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = theano_utils.fc_layer(flattened, 4*4*64, 500)\n",
    "fc1_out = fc1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
