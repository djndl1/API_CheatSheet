#+title: Console

For GUI apps, console must be allocated and freed with =AllocConsole()= and
=FreeConsole()=. A process may have only one console. The console can be
read/written with =ReadFile()= and =WriteFile()= but =ReadConsole()=,
=WriteConsole()= and =SetConsoleMode()= provide console-specific features.
Console I/O operates on characters rather than bytes. =CONIN$= and =CONOUT$= are
special file names that always refer to the console input and output.

* Why Windows Console Is Slow

The Windows Terminal itself is poorly written and renders slowly.
A console app is hosted by a =conhost= process between the child process and its
parent, which handles the three standard I/O handles, adding more IPC overhead.
The Windows console subsystem itself adds overhead as it adds a few preprocessing.

** Reference

- [[https://github.com/cmuratori/refterm/blob/main/faq.md][Refterm FAQ]]

* Unicode

http://archives.miloush.net/michkap/archive/2010/10/07/10072032.html

http://illegalargumentexception.blogspot.com/2009/04/i18n-unicode-at-windows-command-prompt.html

http://illegalargumentexception.blogspot.com/2009/04/java-unicode-on-windows-command-line.html

https://alfps.wordpress.com/2011/11/22/unicode-part-1-windows-console-io-approaches/

https://devblogs.microsoft.com/cppblog/new-options-for-managing-character-sets-in-the-microsoft-cc-compiler/

The underlying I/O on Windows is based on UTF-16. Any text-mode output goes through
a byte-oriented interface has to be converted based on the current code page.
However, on Windows, stdio goes through the ANSI version of Win32 API
and that is why even =wprintf= on Windows is affected by the current code page
(and twice).

There are two conversions for wide strings (wide-to-narrow in the CRT and
narrow-to-UTF16 by Win32),
and one for byte strings (narrow-to-UTF16 by Win32).
For wide strings, they are first converted to the code page charset, i.e. as
byte strings. The byte strings are then sent into the ANSI Win32 API and
converted there into UTF-16 and fed into the Unicode version.
Data loss during conversion mostly occurs from wide strings to narrow. As long
as the code page matches the narrow strings' charset, the second conversion from
narrow to UTF-16 always works.

The "C" locale on Windows set on startup treats byte strings as their byte
values and uses ASCII as the charset.

MSVC internally use UTF-8 for string literals. For unprefixed string
literals, MSVC would treat them based on the current code page.

Normal strings are output as they are in execution charset (GCC or
MSVC). Execution character sets affect normal byte strings only.

The following code should have the commented standard-conformant result.

#+BEGIN_SRC C++
#include <stdio.h>
#include <wchar.h>
#include <locale.h>

const wchar_t *Test1 = L"Aō中文\n";
const char *Test2 = "Aō中文\n";

void print()
{
	printf("printf-s-1 %s\n", Test2);
}

void wprint()
{
	wprintf(L"wprintf-ls-1 %ls\n", Test1);
}

int main()
{
    setlocale(LC_ALL, "C");
    // with "C", garbled during the first conversion
    // with GB2312, first UTF-16 to GB2312, then GB2312 to UTF-16, no loss
    // with ja_JP, the kanji are fine, the macron o is lost
	wprint();

    // note that these two calls may not be mixed in a single process

    // only ANSI to UTF-16 or even none
    // with "C", seems to output as is without conversion,
    //           whether the console shows it well or not depends on the chcp setting
    // with "zh_CN", completely garbled as the input is UTF-8, not GB2312
    //               set the execution charset to GBK and now it converts correctly to UTF-16
    // with "en_US", garbled in a different way, seems to be Latin-1
    printf();
}
#+END_SRC

The moral is to use ="C"=  and output everything in UTF-8.

=std::cout= and =std::wcout= works in a similar way to =printf("%s")=
and =wprintf("%ls")=.
